<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2021-03-14T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.06885" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.06915" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.06922" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.06927" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.06936" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.06937" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.06939" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.06950" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.06966" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.06967" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.06972" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.06995" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07009" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07013" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07016" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07018" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07020" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07040" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07050" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07052" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07055" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07062" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07066" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07079" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07080" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07084" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07101" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07113" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07117" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07125" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07150" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07155" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07156" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07162" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07176" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07184" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07186" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07197" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07206" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07208" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07220" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07223" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07224" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07245" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07248" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07262" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07268" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07276" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07279" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07281" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07286" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07287" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07292" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07295" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07297" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07303" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07350" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07364" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07388" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07405" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07423" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07445" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07453" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07454" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.07458" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1808.06942" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.02220" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1906.02325" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1910.03471" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1911.09721" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1912.08881" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2001.05876" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2003.04774" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2004.03734" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2005.12420" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2006.02479" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2006.03031" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2006.06983" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2006.07701" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2006.09359" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2007.05239" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2007.08637" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2007.14535" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2008.05859" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2008.07257" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2008.12416" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2009.06456" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2009.09143" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2009.11162" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2010.04925" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2010.05265" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2010.08262" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2010.08277" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2011.03037" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2011.15102" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2012.04461" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2012.04863" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2012.13681" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2101.02494" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2101.08685" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2101.10437" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2102.06483" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2102.08093" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.02826" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.04551" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.04564" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.05030" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.05863" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.06369" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.06727" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2103.06885">
<title>Modern Dimension Reduction. (arXiv:2103.06885v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.06885</link>
<description rdf:parseType="Literal">&lt;p&gt;Data are not only ubiquitous in society, but are increasingly complex both in
size and dimensionality. Dimension reduction offers researchers and scholars
the ability to make such complex, high dimensional data spaces simpler and more
manageable. This Element offers readers a suite of modern unsupervised
dimension reduction techniques along with hundreds of lines of R code, to
efficiently represent the original high dimensional data space in a simplified,
lower dimensional subspace. Launching from the earliest dimension reduction
technique principal components analysis and using real social science data, I
introduce and walk readers through application of the following techniques:
locally linear embedding, t-distributed stochastic neighbor embedding (t-SNE),
uniform manifold approximation and projection, self-organizing maps, and deep
autoencoders. The result is a well-stocked toolbox of unsupervised algorithms
for tackling the complexities of high dimensional data so common in modern
society. All code is publicly accessible on Github.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Waggoner_P/0/1/0/all/0/1&quot;&gt;Philip D. Waggoner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.06915">
<title>On Improving Deep Learning Trace Analysis with System Call Arguments. (arXiv:2103.06915v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.06915</link>
<description rdf:parseType="Literal">&lt;p&gt;Kernel traces are sequences of low-level events comprising a name and
multiple arguments, including a timestamp, a process id, and a return value,
depending on the event. Their analysis helps uncover intrusions, identify bugs,
and find latency causes. However, their effectiveness is hindered by omitting
the event arguments. To remedy this limitation, we introduce a general approach
to learning a representation of the event names along with their arguments
using both embedding and encoding. The proposed method is readily applicable to
most neural networks and is task-agnostic. The benefit is quantified by
conducting an ablation study on three groups of arguments: call-related,
process-related, and time-related. Experiments were conducted on a novel web
request dataset and validated on a second dataset collected on pre-production
servers by Ciena, our partnering company. By leveraging additional information,
we were able to increase the performance of two widely-used neural networks, an
LSTM and a Transformer, by up to 11.3% on two unsupervised language modelling
tasks. Such tasks may be used to detect anomalies, pre-train neural networks to
improve their performance, and extract a contextual representation of the
events.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fournier_Q/0/1/0/all/0/1&quot;&gt;Quentin Fournier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aloise_D/0/1/0/all/0/1&quot;&gt;Daniel Aloise&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azhari_S/0/1/0/all/0/1&quot;&gt;Seyed Vahid Azhari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tetreault_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Tetreault&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.06922">
<title>Towards Interpreting and Mitigating Shortcut Learning Behavior of NLU models. (arXiv:2103.06922v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2103.06922</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent studies indicate that NLU models are prone to rely on shortcut
features for prediction. As a result, these models could potentially fail to
generalize to real-world out-of-distribution scenarios. In this work, we show
that the shortcut learning behavior can be explained by the long-tailed
phenomenon. There are two findings : 1) Trained NLU models have strong
preference for features located at the head of the long-tailed distribution,
and 2) Shortcut features are picked up during very early few iterations of the
model training. These two observations are further employed to formulate a
measurement which can quantify the shortcut degree of each training sample.
Based on this shortcut measurement, we propose a shortcut mitigation framework,
to suppress the model from making overconfident predictions for samples with
large shortcut degree. Experimental results on three NLU benchmarks demonstrate
that our long-tailed distribution explanation accurately reflects the shortcut
learning behavior of NLU models. Experimental analysis further indicates that
our method can improve the generalization accuracy on OOD data, while
preserving the accuracy on in distribution test data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1&quot;&gt;Mengnan Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manjunatha_V/0/1/0/all/0/1&quot;&gt;Varun Manjunatha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1&quot;&gt;Rajiv Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deshpande_R/0/1/0/all/0/1&quot;&gt;Ruchi Deshpande&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dernoncourt_F/0/1/0/all/0/1&quot;&gt;Franck Dernoncourt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1&quot;&gt;Jiuxiang Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1&quot;&gt;Tong Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xia Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.06927">
<title>Linnaeus: A highly reusable and adaptable ML based log classification pipeline. (arXiv:2103.06927v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.06927</link>
<description rdf:parseType="Literal">&lt;p&gt;Logs are a common way to record detailed run-time information in software. As
modern software systems evolve in scale and complexity, logs have become
indispensable to understanding the internal states of the system. At the same
time however, manually inspecting logs has become impractical. In recent times,
there has been more emphasis on statistical and machine learning (ML) based
methods for analyzing logs. While the results have shown promise, most of the
literature focuses on algorithms and state-of-the-art (SOTA), while largely
ignoring the practical aspects. In this paper we demonstrate our end-to-end log
classification pipeline, Linnaeus. Besides showing the more traditional ML
flow, we also demonstrate our solutions for adaptability and re-use,
integration towards large scale software development processes, and how we cope
with lack of labelled data. We hope Linnaeus can serve as a blueprint for, and
inspire the integration of, various ML based solutions in other large scale
industrial settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Catovic_A/0/1/0/all/0/1&quot;&gt;Armin Catovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cartwright_C/0/1/0/all/0/1&quot;&gt;Carolyn Cartwright&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gebreyesus_Y/0/1/0/all/0/1&quot;&gt;Yasmin Tesfaldet Gebreyesus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferlin_S/0/1/0/all/0/1&quot;&gt;Simone Ferlin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.06936">
<title>Stochastic-HMDs: Adversarial Resilient Hardware Malware Detectors through Voltage Over-scaling. (arXiv:2103.06936v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2103.06936</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning-based hardware malware detectors (HMDs) offer a potential
game changing advantage in defending systems against malware. However, HMDs
suffer from adversarial attacks, can be effectively reverse-engineered and
subsequently be evaded, allowing malware to hide from detection. We address
this issue by proposing a novel HMDs (Stochastic-HMDs) through approximate
computing, which makes HMDs&apos; inference computation-stochastic, thereby making
HMDs resilient against adversarial evasion attacks. Specifically, we propose to
leverage voltage overscaling to induce stochastic computation in the HMDs
model. We show that such a technique makes HMDs more resilient to both
black-box adversarial attack scenarios, i.e., reverse-engineering and
transferability. Our experimental results demonstrate that Stochastic-HMDs
offer effective defense against adversarial attacks along with by-product power
savings, without requiring any changes to the hardware/software nor to the
HMDs&apos; model, i.e., no retraining or fine tuning is needed. Moreover, based on
recent results in probably approximately correct (PAC) learnability theory, we
show that Stochastic-HMDs are provably more difficult to reverse engineer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1&quot;&gt;Md Shohidul Islam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alouani_I/0/1/0/all/0/1&quot;&gt;Ihsen Alouani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khasawneh_K/0/1/0/all/0/1&quot;&gt;Khaled N. Khasawneh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.06937">
<title>The Semi-Supervised iNaturalist-Aves Challenge at FGVC7 Workshop. (arXiv:2103.06937v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2103.06937</link>
<description rdf:parseType="Literal">&lt;p&gt;This document describes the details and the motivation behind a new dataset
we collected for the semi-supervised recognition challenge~\cite{semi-aves} at
the FGVC7 workshop at CVPR 2020. The dataset contains 1000 species of birds
sampled from the iNat-2018 dataset for a total of nearly 150k images. From this
collection, we sample a subset of classes and their labels, while adding the
images from the remaining classes to the unlabeled set of images. The presence
of out-of-domain data (novel classes), high class-imbalance, and fine-grained
similarity between classes poses significant challenges for existing
semi-supervised recognition techniques in the literature. The dataset is
available here: \url{https://github.com/cvl-umass/semi-inat-2020}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1&quot;&gt;Jong-Chyi Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maji_S/0/1/0/all/0/1&quot;&gt;Subhransu Maji&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.06939">
<title>A Reinforcement Learning Based Approach to Play Calling in Football. (arXiv:2103.06939v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.06939</link>
<description rdf:parseType="Literal">&lt;p&gt;With the vast amount of data collected on football and the growth of
computing abilities, many games involving decision choices can be optimized.
The underlying rule is the maximization of an expected utility of outcomes and
the law of large numbers. The data available allows us to compute with high
accuracy the probabilities of outcomes of decisions and the well defined points
system in the game allows us to have the necessary terminal utilities. With
some well established theory we can then optimize choices at a single play
level.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biro_P/0/1/0/all/0/1&quot;&gt;Preston Biro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walker_S/0/1/0/all/0/1&quot;&gt;Stephen G. Walker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.06950">
<title>The Minecraft Kernel: Modelling correlated Gaussian Processes in the Fourier domain. (arXiv:2103.06950v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2103.06950</link>
<description rdf:parseType="Literal">&lt;p&gt;In the univariate setting, using the kernel spectral representation is an
appealing approach for generating stationary covariance functions. However,
performing the same task for multiple-output Gaussian processes is
substantially more challenging. We demonstrate that current approaches to
modelling cross-covariances with a spectral mixture kernel possess a critical
blind spot. For a given pair of processes, the cross-covariance is not
reproducible across the full range of permitted correlations, aside from the
special case where their spectral densities are of identical shape. We present
a solution to this issue by replacing the conventional Gaussian components of a
spectral mixture with block components of finite bandwidth (i.e. rectangular
step functions). The proposed family of kernel represents the first
multi-output generalisation of the spectral mixture kernel that can approximate
any stationary multi-output kernel to arbitrary precision.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Simpson_F/0/1/0/all/0/1&quot;&gt;Fergus Simpson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boukouvalas_A/0/1/0/all/0/1&quot;&gt;Alexis Boukouvalas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cadek_V/0/1/0/all/0/1&quot;&gt;Vaclav Cadek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sarkans_E/0/1/0/all/0/1&quot;&gt;Elvijs Sarkans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Durrande_N/0/1/0/all/0/1&quot;&gt;Nicolas Durrande&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.06966">
<title>Efficient Pairwise Neuroimage Analysis using the Soft Jaccard Index and 3D Keypoint Sets. (arXiv:2103.06966v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2103.06966</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel pairwise distance measure between variable sized sets of
image keypoints for the purpose of large-scale medical image indexing. Our
measure generalizes the Jaccard distance to account for soft set equivalence
(SSE) between set elements, via an adaptive kernel framework accounting for
uncertainty in keypoint appearance and geometry. Novel kernels are proposed to
quantify variability of keypoint geometry in location and scale. Our distance
measure may be estimated between $N^2$ image pairs in $O(N~log~N)$ operations
via keypoint indexing. Experiments validate our method in predicting 509,545
pairwise relationships from T1-weighted MRI brain volumes of monozygotic and
dizygotic twins, siblings and half-siblings sharing 100%-25% of their
polymorphic genes. Soft set equivalence and keypoint geometry kernels
outperform standard hard set equivalence (HSE) in predicting family
relationships. High accuracy is achieved, with monozygotic twin identification
near 100% and several cases of unknown family labels, due to errors in the
genotyping process, are correctly paired with family members. Software is
provided for efficient fine-grained curation of large, generic image datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chauvin_L/0/1/0/all/0/1&quot;&gt;Laurent Chauvin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_K/0/1/0/all/0/1&quot;&gt;Kuldeep Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Desrosiers_C/0/1/0/all/0/1&quot;&gt;Christian Desrosiers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wells_W/0/1/0/all/0/1&quot;&gt;William Wells III&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toews_M/0/1/0/all/0/1&quot;&gt;Matthew Toews&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.06967">
<title>Adversarial attacks in consensus-based multi-agent reinforcement learning. (arXiv:2103.06967v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2103.06967</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, many cooperative distributed multi-agent reinforcement learning
(MARL) algorithms have been proposed in the literature. In this work, we study
the effect of adversarial attacks on a network that employs a consensus-based
MARL algorithm. We show that an adversarial agent can persuade all the other
agents in the network to implement policies that optimize an objective that it
desires. In this sense, the standard consensus-based MARL algorithms are
fragile to attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Figura_M/0/1/0/all/0/1&quot;&gt;Martin Figura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kosaraju_K/0/1/0/all/0/1&quot;&gt;Krishna Chaitanya Kosaraju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gupta_V/0/1/0/all/0/1&quot;&gt;Vijay Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.06972">
<title>Federated Functional Gradient Boosting. (arXiv:2103.06972v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.06972</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we initiate a study of functional minimization in Federated
Learning. First, in the semi-heterogeneous setting, when the marginal
distributions of the feature vectors on client machines are identical, we
develop the federated functional gradient boosting (FFGB) method that provably
converges to the global minimum. Subsequently, we extend our results to the
fully-heterogeneous setting (where marginal distributions of feature vectors
may differ) by designing an efficient variant of FFGB called FFGB.C, with
provable convergence to a neighborhood of the global minimum within a radius
that depends on the total variation distances between the client feature
distributions. For the special case of square loss, but still in the fully
heterogeneous setting, we design the FFGB.L method that also enjoys provable
convergence to a neighborhood of the global minimum but within a radius
depending on the much tighter Wasserstein-1 distances. For both FFGB.C and
FFGB.L, the radii of convergence shrink to zero as the feature distributions
become more homogeneous. Finally, we conduct proof-of-concept experiments to
demonstrate the benefits of our approach against natural baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1&quot;&gt;Zebang Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassani_H/0/1/0/all/0/1&quot;&gt;Hamed Hassani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kale_S/0/1/0/all/0/1&quot;&gt;Satyen Kale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karbasi_A/0/1/0/all/0/1&quot;&gt;Amin Karbasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.06995">
<title>Physics and Computing Performance of the Exa.TrkX TrackML Pipeline. (arXiv:2103.06995v1 [hep-ex])</title>
<link>http://arxiv.org/abs/2103.06995</link>
<description rdf:parseType="Literal">&lt;p&gt;The Exa.TrkX project has applied geometric learning concepts such as metric
learning and graph neural networks to HEP particle tracking. The Exa.TrkX
tracking pipeline clusters detector measurements to form track candidates and
filters them. The pipeline, originally developed using the TrackML dataset (a
simulation of an LHC-like tracking detector), has been demonstrated on various
detectors, including the DUNE LArTPC and the CMS High-Granularity Calorimeter.
This paper documents new developments needed to study the physics and computing
performance of the Exa.TrkX pipeline on the full TrackML dataset, a first step
towards validating the pipeline using ATLAS and CMS data. The pipeline achieves
tracking efficiency and purity similar to production tracking algorithms.
Crucially for future HEP applications, the pipeline benefits significantly from
GPU acceleration, and its computational requirements scale close to linearly
with the number of particles in the event.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Ju_X/0/1/0/all/0/1&quot;&gt;Xiangyang Ju&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Murnane_D/0/1/0/all/0/1&quot;&gt;Daniel Murnane&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Calafiura_P/0/1/0/all/0/1&quot;&gt;Paolo Calafiura&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Choma_N/0/1/0/all/0/1&quot;&gt;Nicholas Choma&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Conlon_S/0/1/0/all/0/1&quot;&gt;Sean Conlon&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Farrell_S/0/1/0/all/0/1&quot;&gt;Steve Farrell&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yaoyuan Xu&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Spiropulu_M/0/1/0/all/0/1&quot;&gt;Maria Spiropulu&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Vlimant_J/0/1/0/all/0/1&quot;&gt;Jean-Roch Vlimant&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Aurisano_A/0/1/0/all/0/1&quot;&gt;Adam Aurisano&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Hewes_J/0/1/0/all/0/1&quot;&gt;Jeremy Hewes&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Cerati_G/0/1/0/all/0/1&quot;&gt;Giuseppe Cerati&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Gray_L/0/1/0/all/0/1&quot;&gt;Lindsey Gray&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Klijnsma_T/0/1/0/all/0/1&quot;&gt;Thomas Klijnsma&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Kowalkowski_J/0/1/0/all/0/1&quot;&gt;Jim Kowalkowski&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Atkinson_M/0/1/0/all/0/1&quot;&gt;Markus Atkinson&lt;/a&gt; (5), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Neubauer_M/0/1/0/all/0/1&quot;&gt;Mark Neubauer&lt;/a&gt; (5), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+DeZoort_G/0/1/0/all/0/1&quot;&gt;Gage DeZoort&lt;/a&gt; (6), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Thais_S/0/1/0/all/0/1&quot;&gt;Savannah Thais&lt;/a&gt; (6), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Chauhan_A/0/1/0/all/0/1&quot;&gt;Aditi Chauhan&lt;/a&gt; (7), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Schuy_A/0/1/0/all/0/1&quot;&gt;Alex Schuy&lt;/a&gt; (7), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Hsu_S/0/1/0/all/0/1&quot;&gt;Shih-Chieh Hsu&lt;/a&gt; (7), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Ballow_A/0/1/0/all/0/1&quot;&gt;Alex Ballow&lt;/a&gt; (8), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Lazar_a/0/1/0/all/0/1&quot;&gt;and Alina Lazar&lt;/a&gt; (8) ((1) Lawrence Berkeley National Laboratory, (2) California Institute of Technology, (3) University of Cincinnati, (4) Fermi National Accelerator Laboratory, (5) University of Illinois at Urbana-Champaign, (6) Princeton University, (7) University of Washington, (8) Youngstown State University)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07009">
<title>Learning by Teaching, with Application to Neural Architecture Search. (arXiv:2103.07009v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07009</link>
<description rdf:parseType="Literal">&lt;p&gt;In human learning, an effective skill in improving learning outcomes is
learning by teaching: a learner deepens his/her understanding of a topic by
teaching this topic to others. In this paper, we aim to borrow this
teaching-driven learning methodology from humans and leverage it to train more
performant machine learning models, by proposing a novel ML framework referred
to as learning by teaching (LBT). In the LBT framework, a teacher model
improves itself by teaching a student model to learn well. Specifically, the
teacher creates a pseudo-labeled dataset and uses it to train a student model.
Based on how the student performs on a validation dataset, the teacher
re-learns its model and re-teaches the student until the student achieves great
validation performance. Our framework is based on three-level optimization
which contains three stages: teacher learns; teacher teaches student; teacher
re-learns based on how well the student performs. A simple but efficient
algorithm is developed to solve the three-level optimization problem. We apply
LBT to search neural architectures on CIFAR-10, CIFAR-100, and ImageNet. The
efficacy of our method is demonstrated in various experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheth_P/0/1/0/all/0/1&quot;&gt;Parth Sheth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yueyu Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1&quot;&gt;Pengtao Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07013">
<title>Large Batch Simulation for Deep Reinforcement Learning. (arXiv:2103.07013v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07013</link>
<description rdf:parseType="Literal">&lt;p&gt;We accelerate deep reinforcement learning-based training in visually complex
3D environments by two orders of magnitude over prior work, realizing
end-to-end training speeds of over 19,000 frames of experience per second on a
single GPU and up to 72,000 frames per second on a single eight-GPU machine.
The key idea of our approach is to design a 3D renderer and embodied navigation
simulator around the principle of &quot;batch simulation&quot;: accepting and executing
large batches of requests simultaneously. Beyond exposing large amounts of work
at once, batch simulation allows implementations to amortize in-memory storage
of scene assets, rendering work, data loading, and synchronization costs across
many simulation requests, dramatically improving the number of simulated agents
per GPU and overall simulation throughput. To balance DNN inference and
training costs with faster simulation, we also build a computationally
efficient policy DNN that maintains high task performance, and modify training
algorithms to maintain sample efficiency when training with large mini-batches.
By combining batch simulation and DNN performance optimizations, we demonstrate
that PointGoal navigation agents can be trained in complex 3D environments on a
single GPU in 1.5 days to 97% of the accuracy of agents trained on a prior
state-of-the-art system using a 64-GPU cluster over three days. We provide
open-source reference implementations of our batch 3D renderer and simulator to
facilitate incorporation of these ideas into RL systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shacklett_B/0/1/0/all/0/1&quot;&gt;Brennan Shacklett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wijmans_E/0/1/0/all/0/1&quot;&gt;Erik Wijmans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petrenko_A/0/1/0/all/0/1&quot;&gt;Aleksei Petrenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savva_M/0/1/0/all/0/1&quot;&gt;Manolis Savva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batra_D/0/1/0/all/0/1&quot;&gt;Dhruv Batra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koltun_V/0/1/0/all/0/1&quot;&gt;Vladlen Koltun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fatahalian_K/0/1/0/all/0/1&quot;&gt;Kayvon Fatahalian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07016">
<title>On the Equivalence Between Temporal and Static Graph Representations for Observational Predictions. (arXiv:2103.07016v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07016</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we formalize the (pure observational) task of predicting node
attribute evolution in temporal graphs. We show that node representations of
temporal graphs can be cast into two distinct frameworks: (a) The de-facto
standard approach, which we denote {\em time-and-graph}, where equivariant
graph (e.g., GNN) and sequence (e.g., RNN) representations are intertwined to
represent the temporal evolution of the graph; and (b) an approach that we
denote {\em time-then-graph}, where the sequences describing the node and edge
dynamics are represented first (e.g., RNN), then fed as node and edge
attributes into a (static) equivariant graph representation that comes after
(e.g., GNN). In real-world datasets, we show that our {\em time-then-graph}
framework achieves the same prediction performance as state-of-the-art {\em
time-and-graph} methods. Interestingly, {\em time-then-graph} representations
have an expressiveness advantage over {\em time-and-graph} representations when
both use component GNNs that are not most-expressive (e.g., 1-Weisfeiler-Lehman
GNNs). We introduce a task where this expressiveness advantage allows {\em
time-then-graph} methods to succeed while state-of-the-art {\em time-and-graph}
methods fail.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jianfei Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1&quot;&gt;Bruno Ribeiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07018">
<title>Interleaving Learning, with Application to Neural Architecture Search. (arXiv:2103.07018v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07018</link>
<description rdf:parseType="Literal">&lt;p&gt;Interleaving learning is a human learning technique where a learner
interleaves the studies of multiple topics, which increases long-term retention
and improves ability to transfer learned knowledge. Inspired by the
interleaving learning technique of humans, in this paper we explore whether
this learning methodology is beneficial for improving the performance of
machine learning models as well. We propose a novel machine learning framework
referred to as interleaving learning (IL). In our framework, a set of models
collaboratively learn a data encoder in an interleaving fashion: the encoder is
trained by model 1 for a while, then passed to model 2 for further training,
then model 3, and so on; after trained by all models, the encoder returns back
to model 1 and is trained again, then moving to model 2, 3, etc. This process
repeats for multiple rounds. Our framework is based on multi-level optimization
consisting of multiple inter-connected learning stages. An efficient
gradient-based algorithm is developed to solve the multi-level optimization
problem. We apply interleaving learning to search neural architectures for
image classification on CIFAR-10, CIFAR-100, and ImageNet. The effectiveness of
our method is strongly demonstrated by the experimental results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ban_H/0/1/0/all/0/1&quot;&gt;Hao Ban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1&quot;&gt;Pengtao Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07020">
<title>Max-Linear Regression by Scalable and Guaranteed Convex Programming. (arXiv:2103.07020v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2103.07020</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the multivariate max-linear regression problem where the model
parameters
$\boldsymbol{\beta}_{1},\dotsc,\boldsymbol{\beta}_{k}\in\mathbb{R}^{p}$ need to
be estimated from $n$ independent samples of the (noisy) observations $y =
\max_{1\leq j \leq k} \boldsymbol{\beta}_{j}^{\mathsf{T}} \boldsymbol{x} +
\mathrm{noise}$. The max-linear model vastly generalizes the conventional
linear model, and it can approximate any convex function to an arbitrary
accuracy when the number of linear models $k$ is large enough. However, the
inherent nonlinearity of the max-linear model renders the estimation of the
regression parameters computationally challenging. Particularly, no estimator
based on convex programming is known in the literature. We formulate and
analyze a scalable convex program as the estimator for the max-linear
regression problem. Under the standard Gaussian observation setting, we present
a non-asymptotic performance guarantee showing that the convex program recovers
the parameters with high probability. When the $k$ linear components are
equally likely to achieve the maximum, our result shows that a sufficient
number of observations scales as $k^{2}p$ up to a logarithmic factor. This
significantly improves on the analogous prior result based on alternating
minimization (Ghosh et al., 2019). Finally, through a set of Monte Carlo
simulations, we illustrate that our theoretical result is consistent with
empirical behavior, and the convex estimator for max-linear regression is as
competitive as the alternating minimization algorithm in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Seonho Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bahmani_S/0/1/0/all/0/1&quot;&gt;Sohail Bahmani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kiryung Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07040">
<title>Bilingual Dictionary-based Language Model Pretraining for Neural Machine Translation. (arXiv:2103.07040v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2103.07040</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent studies have demonstrated a perceivable improvement on the performance
of neural machine translation by applying cross-lingual language model
pretraining (Lample and Conneau, 2019), especially the Translation Language
Modeling (TLM). To alleviate the need for expensive parallel corpora by TLM, in
this work, we incorporate the translation information from dictionaries into
the pretraining process and propose a novel Bilingual Dictionary-based Language
Model (BDLM). We evaluate our BDLM in Chinese, English, and Romanian. For
Chinese-English, we obtained a 55.0 BLEU on WMT-News19 (Tiedemann, 2012) and a
24.3 BLEU on WMT20 news-commentary, outperforming the Vanilla Transformer
(Vaswani et al., 2017) by more than 8.4 BLEU and 2.3 BLEU, respectively.
According to our results, the BDLM also has advantages on convergence speed and
predicting rare words. The increase in BLEU for WMT16 Romanian-English also
shows its effectiveness in low-resources language translation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1&quot;&gt;Yusen Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Jiayong Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shuaicheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1&quot;&gt;Haoying Dai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07050">
<title>SCEI: A Smart-Contract Driven Edge Intelligence Framework for IoT Systems. (arXiv:2103.07050v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07050</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) utilizes edge computing devices to collaboratively
train a shared model while each device can fully control its local data access.
Generally, FL techniques focus on learning model on independent and identically
distributed (iid) dataset and cannot achieve satisfiable performance on non-iid
datasets (e.g. learning a multi-class classifier but each client only has a
single class dataset). Some personalized approaches have been proposed to
mitigate non-iid issues. However, such approaches cannot handle underlying data
distribution shift, namely data distribution skew, which is quite common in
real scenarios (e.g. recommendation systems learn user behaviors which change
over time). In this work, we provide a solution to the challenge by leveraging
smart-contract with federated learning to build optimized, personalized deep
learning models. Specifically, our approach utilizes smart contract to reach
consensus among distributed trainers on the optimal weights of personalized
models. We conduct experiments across multiple models (CNN and MLP) and
multiple datasets (MNIST and CIFAR-10). The experimental results demonstrate
that our personalized learning models can achieve better accuracy and faster
convergence compared to classic federated and personalized learning. Compared
with the model given by baseline FedAvg algorithm, the average accuracy of our
personalized learning models is improved by 2% to 20%, and the convergence rate
is about 2$\times$ faster. Moreover, we also illustrate that our approach is
secure against recent attack on distributed learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Chenhao Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1&quot;&gt;Yao Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_J/0/1/0/all/0/1&quot;&gt;Jiaqi Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1&quot;&gt;Longxiang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mengshi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1&quot;&gt;Yong Xiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1&quot;&gt;Xi Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07052">
<title>Improving Authorship Verification using Linguistic Divergence. (arXiv:2103.07052v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2103.07052</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an unsupervised solution to the Authorship Verification task that
utilizes pre-trained deep language models to compute a new metric called
DV-Distance. The proposed metric is a measure of the difference between the two
authors comparing against pre-trained language models. Our design addresses the
problem of non-comparability in authorship verification, frequently encountered
in small or cross-domain corpora. To the best of our knowledge, this paper is
the first one to introduce a method designed with non-comparability in mind
from the ground up, rather than indirectly. It is also one of the first to use
Deep Language Models in this setting. The approach is intuitive, and it is easy
to understand and interpret through visualization. Experiments on four datasets
show our methods matching or surpassing current state-of-the-art and strong
baselines in most tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yifan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boumber_D/0/1/0/all/0/1&quot;&gt;Dainis Boumber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hosseinia_M/0/1/0/all/0/1&quot;&gt;Marjan Hosseinia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1&quot;&gt;Fan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1&quot;&gt;Arjun Mukherjee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07055">
<title>Vision Transformer for COVID-19 CXR Diagnosis using Chest X-ray Feature Corpus. (arXiv:2103.07055v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2103.07055</link>
<description rdf:parseType="Literal">&lt;p&gt;Under the global COVID-19 crisis, developing robust diagnosis algorithm for
COVID-19 using CXR is hampered by the lack of the well-curated COVID-19 data
set, although CXR data with other disease are abundant. This situation is
suitable for vision transformer architecture that can exploit the abundant
unlabeled data using pre-training. However, the direct use of existing vision
transformer that uses the corpus generated by the ResNet is not optimal for
correct feature embedding. To mitigate this problem, we propose a novel vision
Transformer by using the low-level CXR feature corpus that are obtained to
extract the abnormal CXR features. Specifically, the backbone network is
trained using large public datasets to obtain the abnormal features in routine
diagnosis such as consolidation, glass-grass opacity (GGO), etc. Then, the
embedded features from the backbone network are used as corpus for vision
transformer training. We examine our model on various external test datasets
acquired from totally different institutions to assess the generalization
ability. Our experiments demonstrate that our method achieved the state-of-art
performance and has better generalization capability, which are crucial for a
widespread deployment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Sangjoon Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_G/0/1/0/all/0/1&quot;&gt;Gwanghyun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Oh_Y/0/1/0/all/0/1&quot;&gt;Yujin Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Seo_J/0/1/0/all/0/1&quot;&gt;Joon Beom Seo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Sang Min Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jin Hwan Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Moon_S/0/1/0/all/0/1&quot;&gt;Sungjun Moon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lim_J/0/1/0/all/0/1&quot;&gt;Jae-Kwang Lim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jong Chul Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07062">
<title>Severity Quantification and Lesion Localization of COVID-19 on CXR using Vision Transformer. (arXiv:2103.07062v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2103.07062</link>
<description rdf:parseType="Literal">&lt;p&gt;Under the global pandemic of COVID-19, building an automated framework that
quantifies the severity of COVID-19 and localizes the relevant lesion on chest
X-ray images has become increasingly important. Although pixel-level lesion
severity labels, e.g. lesion segmentation, can be the most excellent target to
build a robust model, collecting enough data with such labels is difficult due
to time and labor-intensive annotation tasks. Instead, array-based severity
labeling that assigns integer scores on six subdivisions of lungs can be an
alternative choice enabling the quick labeling. Several groups proposed deep
learning algorithms that quantify the severity of COVID-19 using the
array-based COVID-19 labels and localize the lesions with explainability maps.
To further improve the accuracy and interpretability, here we propose a novel
Vision Transformer tailored for both quantification of the severity and
clinically applicable localization of the COVID-19 related lesions. Our model
is trained in a weakly-supervised manner to generate the full probability maps
from weak array-based labels. Furthermore, a novel progressive self-training
method enables us to build a model with a small labeled dataset. The
quantitative and qualitative analysis on the external testset demonstrates that
our method shows comparable performance with radiologists for both tasks with
stability in a real-world application.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_G/0/1/0/all/0/1&quot;&gt;Gwanghyun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Sangjoon Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Oh_Y/0/1/0/all/0/1&quot;&gt;Yujin Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Seo_J/0/1/0/all/0/1&quot;&gt;Joon Beom Seo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Sang Min Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jin Hwan Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Moon_S/0/1/0/all/0/1&quot;&gt;Sungjun Moon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lim_J/0/1/0/all/0/1&quot;&gt;Jae-Kwang Lim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jong Chul Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07066">
<title>Evidence-Based Policy Learning. (arXiv:2103.07066v1 [econ.EM])</title>
<link>http://arxiv.org/abs/2103.07066</link>
<description rdf:parseType="Literal">&lt;p&gt;The past years have seen seen the development and deployment of
machine-learning algorithms to estimate personalized treatment-assignment
policies from randomized controlled trials. Yet such algorithms for the
assignment of treatment typically optimize expected outcomes without taking
into account that treatment assignments are frequently subject to hypothesis
testing. In this article, we explicitly take significance testing of the effect
of treatment-assignment policies into account, and consider assignments that
optimize the probability of finding a subset of individuals with a
statistically significant positive treatment effect. We provide an efficient
implementation using decision trees, and demonstrate its gain over selecting
subsets based on positive (estimated) treatment effects. Compared to standard
tree-based regression and classification tools, this approach tends to yield
substantially higher power in detecting subgroups with positive treatment
effects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Spiess_J/0/1/0/all/0/1&quot;&gt;Jann Spiess&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Syrgkanis_V/0/1/0/all/0/1&quot;&gt;Vasilis Syrgkanis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07079">
<title>Can Single-Shuffle SGD be Better than Reshuffling SGD and GD?. (arXiv:2103.07079v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07079</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose matrix norm inequalities that extend the Recht-R\&apos;e (2012)
conjecture on a noncommutative AM-GM inequality by supplementing it with
another inequality that accounts for single-shuffle, which is a widely used
without-replacement sampling scheme that shuffles only once in the beginning
and is overlooked in the Recht-R\&apos;e conjecture. Instead of general positive
semidefinite matrices, we restrict our attention to positive definite matrices
with small enough condition numbers, which are more relevant to matrices that
arise in the analysis of SGD. For such matrices, we conjecture that the means
of matrix products corresponding to with- and without-replacement variants of
SGD satisfy a series of spectral norm inequalities that can be summarized as:
&quot;single-shuffle SGD converges faster than random-reshuffle SGD, which is in
turn faster than with-replacement SGD.&quot; We present theorems that support our
conjecture by proving several special cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yun_C/0/1/0/all/0/1&quot;&gt;Chulhee Yun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sra_S/0/1/0/all/0/1&quot;&gt;Suvrit Sra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jadbabaie_A/0/1/0/all/0/1&quot;&gt;Ali Jadbabaie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07080">
<title>DynACPD Embedding Algorithm for Prediction Tasks in Dynamic Networks. (arXiv:2103.07080v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2103.07080</link>
<description rdf:parseType="Literal">&lt;p&gt;Classical network embeddings create a low dimensional representation of the
learned relationships between features across nodes. Such embeddings are
important for tasks such as link prediction and node classification. In the
current paper, we consider low dimensional embeddings of dynamic networks, that
is a family of time varying networks where there exist both temporal and
spatial link relationships between nodes. We present novel embedding methods
for a dynamic network based on higher order tensor decompositions for tensorial
representations of the dynamic network. In one sense, our embeddings are
analogous to spectral embedding methods for static networks. We provide a
rationale for our algorithms via a mathematical analysis of some potential
reasons for their effectiveness. Finally, we demonstrate the power and
efficiency of our approach by comparing our algorithms&apos; performance on the link
prediction task against an array of current baseline methods across three
distinct real-world dynamic networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Connell_C/0/1/0/all/0/1&quot;&gt;Chris Connell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07084">
<title>Discovering Diverse Solutions in Deep Reinforcement Learning. (arXiv:2103.07084v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2103.07084</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) algorithms are typically limited to learning a
single solution of a specified task, even though there often exists diverse
solutions to a given task. Compared with learning a single solution, learning a
set of diverse solutions is beneficial because diverse solutions enable robust
few-shot adaptation and allow the user to select a preferred solution. Although
previous studies have showed that diverse behaviors can be modeled with a
policy conditioned on latent variables, an approach for modeling an infinite
set of diverse solutions with continuous latent variables has not been
investigated. In this study, we propose an RL method that can learn infinitely
many solutions by training a policy conditioned on a continuous or discrete
low-dimensional latent variable. Through continuous control tasks, we
demonstrate that our method can learn diverse solutions in a data-efficient
manner and that the solutions can be used for few-shot adaptation to solve
unseen tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Osa_T/0/1/0/all/0/1&quot;&gt;Takayuki Osa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tangkaratt_V/0/1/0/all/0/1&quot;&gt;Voot Tangkaratt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07101">
<title>On the (In)Feasibility of Attribute Inference Attacks on Machine Learning Models. (arXiv:2103.07101v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07101</link>
<description rdf:parseType="Literal">&lt;p&gt;With an increase in low-cost machine learning APIs, advanced machine learning
models may be trained on private datasets and monetized by providing them as a
service. However, privacy researchers have demonstrated that these models may
leak information about records in the training dataset via membership inference
attacks. In this paper, we take a closer look at another inference attack
reported in literature, called attribute inference, whereby an attacker tries
to infer missing attributes of a partially known record used in the training
dataset by accessing the machine learning model as an API. We show that even if
a classification model succumbs to membership inference attacks, it is unlikely
to be susceptible to attribute inference attacks. We demonstrate that this is
because membership inference attacks fail to distinguish a member from a nearby
non-member. We call the ability of an attacker to distinguish the two (similar)
vectors as strong membership inference. We show that membership inference
attacks cannot infer membership in this strong setting, and hence inferring
attributes is infeasible. However, under a relaxed notion of attribute
inference, called approximate attribute inference, we show that it is possible
to infer attributes close to the true attributes. We verify our results on
three publicly available datasets, five membership, and three attribute
inference attacks reported in literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1&quot;&gt;Benjamin Zi Hao Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1&quot;&gt;Aviral Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coburn_C/0/1/0/all/0/1&quot;&gt;Catisha Coburn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asghar_H/0/1/0/all/0/1&quot;&gt;Hassan Jameel Asghar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhaskar_R/0/1/0/all/0/1&quot;&gt;Raghav Bhaskar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaafar_M/0/1/0/all/0/1&quot;&gt;Mohamed Ali Kaafar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Webb_D/0/1/0/all/0/1&quot;&gt;Darren Webb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dickinson_P/0/1/0/all/0/1&quot;&gt;Peter Dickinson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07113">
<title>Training Networks in Null Space of Covariance for Continual Learning. (arXiv:2103.07113v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07113</link>
<description rdf:parseType="Literal">&lt;p&gt;In the setting of continual learning, a network is trained on a sequence of
tasks, and suffers from catastrophic forgetting. To balance plasticity and
stability of network in continual learning, in this paper, we propose a novel
network training algorithm called Adam-NSCL, which sequentially optimizes
network parameters in the null space of previous tasks. We first propose two
mathematical conditions respectively for achieving network stability and
plasticity in continual learning. Based on them, the network training for
sequential tasks can be simply achieved by projecting the candidate parameter
update into the approximate null space of all previous tasks in the network
training process, where the candidate parameter update can be generated by
Adam. The approximate null space can be derived by applying singular value
decomposition to the uncentered covariance matrix of all input features of
previous tasks for each linear layer. For efficiency, the uncentered covariance
matrix can be incrementally computed after learning each task. We also
empirically verify the rationality of the approximate null space at each linear
layer. We apply our approach to training networks for continual learning on
benchmark datasets of CIFAR-100 and TinyImageNet, and the results suggest that
the proposed approach outperforms or matches the state-ot-the-art continual
learning approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shipeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaorong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jian Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zongben Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07117">
<title>GA for feature selection of EEG heterogeneous data. (arXiv:2103.07117v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2103.07117</link>
<description rdf:parseType="Literal">&lt;p&gt;The electroencephalographic (EEG) signals provide highly informative data on
brain activities and functions. However, their heterogeneity and high
dimensionality may represent an obstacle for their interpretation. The
introduction of a priori knowledge seems the best option to mitigate high
dimensionality problems, but could lose some information and patterns present
in the data, while data heterogeneity remains an open issue that often makes
generalization difficult. In this study, we propose a genetic algorithm (GA)
for feature selection that can be used with a supervised or unsupervised
approach. Our proposal considers three different fitness functions without
relying on expert knowledge. Starting from two publicly available datasets on
cognitive workload and motor movement/imagery, the EEG signals are processed,
normalized and their features computed in the time, frequency and
time-frequency domains. The feature vector selection is performed by applying
our GA proposal and compared with two benchmarking techniques. The results show
that different combinations of our proposal achieve better results in respect
to the benchmark in terms of overall performance and feature reduction.
Moreover, the proposed GA, based on a novel fitness function here presented,
outperforms the benchmark when the two different datasets considered are merged
together, showing the effectiveness of our proposal on heterogeneous data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saibene_A/0/1/0/all/0/1&quot;&gt;Aurora Saibene&lt;/a&gt; (1 and 2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gasparini_F/0/1/0/all/0/1&quot;&gt;Francesca Gasparini&lt;/a&gt; (1 and 2) ((1) University of Milano-Bicocca, Department of Informatics, Systems and Communications, Multi Media Signal Processing Laboratory, (2) University of Milano-Bicocca, NeuroMI)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07125">
<title>Learning spectro-temporal representations of complex sounds with parameterized neural networks. (arXiv:2103.07125v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2103.07125</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Learning models have become potential candidates for auditory
neuroscience research, thanks to their recent successes on a variety of
auditory tasks. Yet, these models often lack interpretability to fully
understand the exact computations that have been performed. Here, we proposed a
parametrized neural network layer, that computes specific spectro-temporal
modulations based on Gabor kernels (Learnable STRFs) and that is fully
interpretable. We evaluated predictive capabilities of this layer on Speech
Activity Detection, Speaker Verification, Urban Sound Classification and Zebra
Finch Call Type Classification. We found out that models based on Learnable
STRFs are on par for all tasks with different toplines, and obtain the best
performance for Speech Activity Detection. As this layer is fully
interpretable, we used quantitative measures to describe the distribution of
the learned spectro-temporal modulations. The filters adapted to each task and
focused mostly on low temporal and spectral modulations. The analyses show that
the filters learned on human speech have similar spectro-temporal parameters as
the ones measured directly in the human auditory cortex. Finally, we observed
that the tasks organized in a meaningful way: the human vocalizations tasks
closer to each other and bird vocalizations far away from human vocalizations
and urban sounds tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riad_R/0/1/0/all/0/1&quot;&gt;Rachid Riad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karadayi_J/0/1/0/all/0/1&quot;&gt;Julien Karadayi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bachoud_Levi_A/0/1/0/all/0/1&quot;&gt;Anne-Catherine Bachoud-L&amp;#xe9;vi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dupoux_E/0/1/0/all/0/1&quot;&gt;Emmanuel Dupoux&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07150">
<title>Auction Based Clustered Federated Learning in Mobile Edge Computing System. (arXiv:2103.07150v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07150</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, mobile clients&apos; computing ability and storage capacity have
greatly improved, efficiently dealing with some applications locally. Federated
learning is a promising distributed machine learning solution that uses local
computing and local data to train the Artificial Intelligence (AI) model.
Combining local computing and federated learning can train a powerful AI model
under the premise of ensuring local data privacy while making full use of
mobile clients&apos; resources. However, the heterogeneity of local data, that is,
Non-independent and identical distribution (Non-IID) and imbalance of local
data size, may bring a bottleneck hindering the application of federated
learning in mobile edge computing (MEC) system. Inspired by this, we propose a
cluster-based clients selection method that can generate a federated virtual
dataset that satisfies the global distribution to offset the impact of data
heterogeneity and proved that the proposed scheme could converge to an
approximate optimal solution. Based on the clustering method, we propose an
auction-based clients selection scheme within each cluster that fully considers
the system&apos;s energy heterogeneity and gives the Nash equilibrium solution of
the proposed scheme for balance the energy consumption and improving the
convergence rate. The simulation results show that our proposed selection
methods and auction-based federated learning can achieve better performance
with the Convolutional Neural Network model (CNN) under different data
distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1&quot;&gt;Renhao Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weizhe Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qiong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_X/0/1/0/all/0/1&quot;&gt;Xiaoxiong Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasilakos_A/0/1/0/all/0/1&quot;&gt;Athanasios V. Vasilakos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07155">
<title>Explainable AI by BAPC -- Before and After correction Parameter Comparison. (arXiv:2103.07155v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2103.07155</link>
<description rdf:parseType="Literal">&lt;p&gt;By means of a local surrogate approach, an analytical method to yield
explanations of AI-predictions in the framework of regression models is
defined. In the case of the AI-model producing additive corrections to the
predictions of a base model, the explanations are delivered in the form of a
shift of its interpretable parameters as long as the AI- predictions are small
in a rigorously defined sense. Criteria are formulated giving a precise
relation between lost accuracy and lacking model fidelity. Two applications
show how physical or econometric parameters may be used to interpret the action
of neural network and random forest models in the sense of the underlying base
model. This is an extended version of our paper presented at the ISM 2020
conference, where we first introduced our new approach BAPC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sobieczky_F/0/1/0/all/0/1&quot;&gt;Florian Sobieczky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mahmoud_S/0/1/0/all/0/1&quot;&gt;Salma Mahmoud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Neugebauer_S/0/1/0/all/0/1&quot;&gt;Simon Neugebauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rippitsch_L/0/1/0/all/0/1&quot;&gt;Lukas Rippitsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Geiss_M/0/1/0/all/0/1&quot;&gt;Manuela Gei&amp;#xdf;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07156">
<title>Learnable Companding Quantization for Accurate Low-bit Neural Networks. (arXiv:2103.07156v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2103.07156</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantizing deep neural networks is an effective method for reducing memory
consumption and improving inference speed, and is thus useful for
implementation in resource-constrained devices. However, it is still hard for
extremely low-bit models to achieve accuracy comparable with that of
full-precision models. To address this issue, we propose learnable companding
quantization (LCQ) as a novel non-uniform quantization method for 2-, 3-, and
4-bit models. LCQ jointly optimizes model weights and learnable companding
functions that can flexibly and non-uniformly control the quantization levels
of weights and activations. We also present a new weight normalization
technique that allows more stable training for quantization. Experimental
results show that LCQ outperforms conventional state-of-the-art methods and
narrows the gap between quantized and full-precision models for image
classification and object detection tasks. Notably, the 2-bit ResNet-50 model
on ImageNet achieves top-1 accuracy of 75.1% and reduces the gap to 1.7%,
allowing LCQ to further exploit the potential of non-uniform quantization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamamoto_K/0/1/0/all/0/1&quot;&gt;Kohei Yamamoto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07162">
<title>Is BERT a Cross-Disciplinary Knowledge Learner? A Surprising Finding of Pre-trained Models&apos; Transferability. (arXiv:2103.07162v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2103.07162</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we investigate whether the power of the models pre-trained on
text data, such as BERT, can be transferred to general token sequence
classification applications. To verify pre-trained models&apos; transferability, we
test the pre-trained models on (1) text classification tasks with meanings of
tokens mismatches, and (2) real-world non-text token sequence classification
data, including amino acid sequence, DNA sequence, and music. We find that even
on non-text data, the models pre-trained on text converge faster than the
randomly initialized models, and the testing performance of the pre-trained
models is merely slightly worse than the models designed for the specific
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kao_W/0/1/0/all/0/1&quot;&gt;Wei-Tsung Kao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hung-Yi Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07176">
<title>Visualising Deep Network&apos;s Time-Series Representations. (arXiv:2103.07176v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07176</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the popularisation of the machine learning models, more often than
not they still operate as black boxes with no insight into what is happening
inside the model. There exist a few methods that allow to visualise and explain
why the model has made a certain prediction. Those methods, however, allow
viewing the causal link between the input and output of the model without
presenting how the model learns to represent the data. In this paper, a method
that addresses that issue is proposed, with a focus on visualising
multi-dimensional time-series data. Experiments on a high-frequency stock
market dataset show that the method provides fast and discernible
visualisations. Large datasets can be visualised quickly and on one plot, which
makes it easy for a user to compare the learned representations of the data.
The developed method successfully combines known and proven techniques to
provide novel insight into the inner workings of time-series classifier models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leporowski_B/0/1/0/all/0/1&quot;&gt;B&amp;#x142;a&amp;#x17c;ej Leporowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1&quot;&gt;Alexandros Iosifidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07184">
<title>Process Comparison Using Object-Centric Process Cubes. (arXiv:2103.07184v1 [cs.DB])</title>
<link>http://arxiv.org/abs/2103.07184</link>
<description rdf:parseType="Literal">&lt;p&gt;Process mining provides ways to analyze business processes. Common process
mining techniques consider the process as a whole. However, in real-life
business processes, different behaviors exist that make the overall process too
complex to interpret. Process comparison is a branch of process mining that
isolates different behaviors of the process from each other by using process
cubes. Process cubes organize event data using different dimensions. Each cell
contains a set of events that can be used as an input to apply process mining
techniques. Existing work on process cubes assume single case notions. However,
in real processes, several case notions (e.g., order, item, package, etc.) are
intertwined. Object-centric process mining is a new branch of process mining
addressing multiple case notions in a process. To make a bridge between
object-centric process mining and process comparison, we propose a process cube
framework, which supports process cube operations such as slice and dice on
object-centric event logs. To facilitate the comparison, the framework is
integrated with several object-centric process discovery approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghahfarokhi_A/0/1/0/all/0/1&quot;&gt;Anahita Farhang Ghahfarokhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berti_A/0/1/0/all/0/1&quot;&gt;Alessandro Berti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aalst_W/0/1/0/all/0/1&quot;&gt;Wil M.P. van der Aalst&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07186">
<title>Dynamic Acoustic Unit Augmentation With BPE-Dropout for Low-Resource End-to-End Speech Recognition. (arXiv:2103.07186v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2103.07186</link>
<description rdf:parseType="Literal">&lt;p&gt;With the rapid development of speech assistants, adapting server-intended
automatic speech recognition (ASR) solutions to a direct device has become
crucial. Researchers and industry prefer to use end-to-end ASR systems for
on-device speech recognition tasks. This is because end-to-end systems can be
made resource-efficient while maintaining a higher quality compared to hybrid
systems. However, building end-to-end models requires a significant amount of
speech data. Another challenging task associated with speech assistants is
personalization, which mainly lies in handling out-of-vocabulary (OOV) words.
In this work, we consider building an effective end-to-end ASR system in
low-resource setups with a high OOV rate, embodied in Babel Turkish and Babel
Georgian tasks. To address the aforementioned problems, we propose a method of
dynamic acoustic unit augmentation based on the BPE-dropout technique. It
non-deterministically tokenizes utterances to extend the token&apos;s contexts and
to regularize their distribution for the model&apos;s recognition of unseen words.
It also reduces the need for optimal subword vocabulary size search. The
technique provides a steady improvement in regular and personalized
(OOV-oriented) speech recognition tasks (at least 6% relative WER and 25%
relative F-score) at no additional computational cost. Owing to the use of
BPE-dropout, our monolingual Turkish Conformer established a competitive result
with 22.2% character error rate (CER) and 38.9% word error rate (WER), which is
close to the best published multilingual system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Laptev_A/0/1/0/all/0/1&quot;&gt;Aleksandr Laptev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Andrusenko_A/0/1/0/all/0/1&quot;&gt;Andrei Andrusenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Podluzhny_I/0/1/0/all/0/1&quot;&gt;Ivan Podluzhny&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mitrofanov_A/0/1/0/all/0/1&quot;&gt;Anton Mitrofanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Medennikov_I/0/1/0/all/0/1&quot;&gt;Ivan Medennikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Matveev_Y/0/1/0/all/0/1&quot;&gt;Yuri Matveev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07197">
<title>Latent Space Explorations of Singing Voice Synthesis using DDSP. (arXiv:2103.07197v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2103.07197</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning based singing voice models require large datasets and
lengthy training times. In this work we present a lightweight architecture,
based on the Differentiable Digital Signal Processing (DDSP) library, that is
able to output song-like utterances conditioned only on pitch and amplitude,
after twelve hours of training using small datasets of unprocessed audio. The
results are promising, as both the melody and the singer&apos;s voice are
recognizable. In addition, we present two zero-configuration tools to train new
models and experiment with them. Currently we are exploring the latent space
representation, which is included in the DDSP library, but not in the original
DDSP examples. Our results indicate that the latent space improves both the
identification of the singer as well as the comprehension of the lyrics. Our
code is available at https://github.com/juanalonso/DDSP-singing-experiments
with links to the zero-configuration notebooks, and our sound examples are at
https://juanalonso.github.io/DDSP-singing-experiments/ .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alonso_J/0/1/0/all/0/1&quot;&gt;Juan Alonso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erkut_C/0/1/0/all/0/1&quot;&gt;Cumhur Erkut&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07206">
<title>Medical data wrangling with sequential variational autoencoders. (arXiv:2103.07206v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07206</link>
<description rdf:parseType="Literal">&lt;p&gt;Medical data sets are usually corrupted by noise and missing data. These
missing patterns are commonly assumed to be completely random, but in medical
scenarios, the reality is that these patterns occur in bursts due to sensors
that are off for some time or data collected in a misaligned uneven fashion,
among other causes. This paper proposes to model medical data records with
heterogeneous data types and bursty missing data using sequential variational
autoencoders (VAEs). In particular, we propose a new methodology, the Shi-VAE,
which extends the capabilities of VAEs to sequential streams of data with
missing observations. We compare our model against state-of-the-art solutions
in an intensive care unit database (ICU) and a dataset of passive human
monitoring. Furthermore, we find that standard error metrics such as RMSE are
not conclusive enough to assess temporal models and include in our analysis the
cross-correlation between the ground truth and the imputed signal. We show that
Shi-VAE achieves the best performance in terms of using both metrics, with
lower computational complexity than the GP-VAE model, which is the
state-of-the-art method for medical records.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barrejon_D/0/1/0/all/0/1&quot;&gt;Daniel Barrej&amp;#xf3;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olmos_P/0/1/0/all/0/1&quot;&gt;Pablo M. Olmos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Artes_Rodriguez_A/0/1/0/all/0/1&quot;&gt;Antonio Art&amp;#xe9;s-Rodr&amp;#xed;guez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07208">
<title>In the light of feature distributions: moment matching for Neural Style Transfer. (arXiv:2103.07208v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2103.07208</link>
<description rdf:parseType="Literal">&lt;p&gt;Style transfer aims to render the content of a given image in the
graphical/artistic style of another image. The fundamental concept underlying
NeuralStyle Transfer (NST) is to interpret style as a distribution in the
feature space of a Convolutional Neural Network, such that a desired style can
be achieved by matching its feature distribution. We show that most current
implementations of that concept have important theoretical and practical
limitations, as they only partially align the feature distributions. We propose
a novel approach that matches the distributions more precisely, thus
reproducing the desired style more faithfully, while still being
computationally efficient. Specifically, we adapt the dual form of Central
Moment Discrepancy (CMD), as recently proposed for domain adaptation, to
minimize the difference between the target style and the feature distribution
of the output image. The dual interpretation of this metric explicitly matches
all higher-order centralized moments and is therefore a natural extension of
existing NST methods that only take into account the first and second moments.
Our experiments confirm that the strong theoretical properties also translate
to visually better style transfer, and better disentangle style from semantic
image content.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalischek_N/0/1/0/all/0/1&quot;&gt;Nikolai Kalischek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wegner_J/0/1/0/all/0/1&quot;&gt;Jan Dirk Wegner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schindler_K/0/1/0/all/0/1&quot;&gt;Konrad Schindler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07220">
<title>Real-time Timbre Transfer and Sound Synthesis using DDSP. (arXiv:2103.07220v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2103.07220</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural audio synthesis is an actively researched topic, having yielded a wide
range of techniques that leverages machine learning architectures. Google
Magenta elaborated a novel approach called Differential Digital Signal
Processing (DDSP) that incorporates deep neural networks with preconditioned
digital signal processing techniques, reaching state-of-the-art results
especially in timbre transfer applications. However, most of these techniques,
including the DDSP, are generally not applicable in real-time constraints,
making them ineligible in a musical workflow. In this paper, we present a
real-time implementation of the DDSP library embedded in a virtual synthesizer
as a plug-in that can be used in a Digital Audio Workstation. We focused on
timbre transfer from learned representations of real instruments to arbitrary
sound inputs as well as controlling these models by MIDI. Furthermore, we
developed a GUI for intuitive high-level controls which can be used for
post-processing and manipulating the parameters estimated by the neural
network. We have conducted a user experience test with seven participants
online. The results indicated that our users found the interface appealing,
easy to understand, and worth exploring further. At the same time, we have
identified issues in the timbre transfer quality, in some components we did not
implement, and in installation and distribution of our plugin. The next
iteration of our design will address these issues. Our real-time MATLAB and
JUCE implementations are available at https://github.com/SMC704/juce-ddsp and
https://github.com/SMC704/matlab-ddsp , respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganis_F/0/1/0/all/0/1&quot;&gt;Francesco Ganis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knudesn_E/0/1/0/all/0/1&quot;&gt;Erik Frej Knudesn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyster_S/0/1/0/all/0/1&quot;&gt;S&amp;#xf8;ren V. K. Lyster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Otterbein_R/0/1/0/all/0/1&quot;&gt;Robin Otterbein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sudholt_D/0/1/0/all/0/1&quot;&gt;David S&amp;#xfc;dholt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erkut_C/0/1/0/all/0/1&quot;&gt;Cumhur Erkut&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07223">
<title>Domain Curiosity: Learning Efficient Data Collection Strategies for Domain Adaptation. (arXiv:2103.07223v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07223</link>
<description rdf:parseType="Literal">&lt;p&gt;Domain adaptation is a common problem in robotics, with applications such as
transferring policies from simulation to real world and lifelong learning.
Performing such adaptation, however, requires informative data about the
environment to be available during the adaptation. In this paper, we present
domain curiosity -- a method of training exploratory policies that are
explicitly optimized to provide data that allows a model to learn about the
unknown aspects of the environment. In contrast to most curiosity methods, our
approach explicitly rewards learning, which makes it robust to environment
noise without sacrificing its ability to learn. We evaluate the proposed method
by comparing how much a model can learn about environment dynamics given data
collected by the proposed approach, compared to standard curious and random
policies. The evaluation is performed using a toy environment, two simulated
robot setups, and on a real-world haptic exploration task. The results show
that the proposed method allows data-efficient and accurate estimation of
dynamics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arndt_K/0/1/0/all/0/1&quot;&gt;Karol Arndt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Struckmeier_O/0/1/0/all/0/1&quot;&gt;Oliver Struckmeier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kyrki_V/0/1/0/all/0/1&quot;&gt;Ville Kyrki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07224">
<title>BDD4BNN: A BDD-based Quantitative Analysis Framework for Binarized Neural Networks. (arXiv:2103.07224v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07224</link>
<description rdf:parseType="Literal">&lt;p&gt;Verifying and explaining the behavior of neural networks is becoming
increasingly important, especially when they are deployed in safety-critical
applications. In this paper, we study verification problems for Binarized
Neural Networks (BNNs), the 1-bit quantization of general real-numbered neural
networks. Our approach is to encode BNNs into Binary Decision Diagrams (BDDs),
which is done by exploiting the internal structure of the BNNs. In particular,
we translate the input-output relation of blocks in BNNs to cardinality
constraints which are then encoded by BDDs. Based on the encoding, we develop a
quantitative verification framework for BNNs where precise and comprehensive
analysis of BNNs can be performed. We demonstrate the application of our
framework by providing quantitative robustness analysis and interpretability
for BNNs. We implement a prototype tool BDD4BNN and carry out extensive
experiments which confirm the effectiveness and efficiency of our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yedi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Zhe Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1&quot;&gt;Guangke Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_F/0/1/0/all/0/1&quot;&gt;Fu Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Taolue Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07245">
<title>Projection-based QLP Algorithm for Efficiently Computing Low-Rank Approximation of Matrices. (arXiv:2103.07245v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07245</link>
<description rdf:parseType="Literal">&lt;p&gt;Matrices with low numerical rank are omnipresent in many signal processing
and data analysis applications. The pivoted QLP (p-QLP) algorithm constructs a
highly accurate approximation to an input low-rank matrix. However, it is
computationally prohibitive for large matrices. In this paper, we introduce a
new algorithm termed Projection-based Partial QLP (PbP-QLP) that efficiently
approximates the p-QLP with high accuracy. Fundamental in our work is the
exploitation of randomization and in contrast to the p-QLP, PbP-QLP does not
use the pivoting strategy. As such, PbP-QLP can harness modern computer
architectures, even better than competing randomized algorithms. The efficiency
and effectiveness of our proposed PbP-QLP algorithm are investigated through
various classes of synthetic and real-world data matrices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaloorazi_M/0/1/0/all/0/1&quot;&gt;Maboud F. Kaloorazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jie Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07248">
<title>Knowledge- and Data-driven Services for Energy Systems using Graph Neural Networks. (arXiv:2103.07248v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07248</link>
<description rdf:parseType="Literal">&lt;p&gt;The transition away from carbon-based energy sources poses several challenges
for the operation of electricity distribution systems. Increasing shares of
distributed energy resources (e.g. renewable energy generators, electric
vehicles) and internet-connected sensing and control devices (e.g. smart
heating and cooling) require new tools to support accurate, datadriven decision
making. Modelling the effect of such growing complexity in the electrical grid
is possible in principle using state-of-the-art power-power flow models. In
practice, the detailed information needed for these physical simulations may be
unknown or prohibitively expensive to obtain. Hence, datadriven approaches to
power systems modelling, including feedforward neural networks and
auto-encoders, have been studied to leverage the increasing availability of
sensor data, but have seen limited practical adoption due to lack of
transparency and inefficiencies on large-scale problems. Our work addresses
this gap by proposing a data- and knowledge-driven probabilistic graphical
model for energy systems based on the framework of graph neural networks
(GNNs). The model can explicitly factor in domain knowledge, in the form of
grid topology or physics constraints, thus resulting in sparser architectures
and much smaller parameters dimensionality when compared with traditional
machine-learning models with similar accuracy. Results obtained from a
real-world smart-grid demonstration project show how the GNN was used to inform
grid congestion predictions and market bidding services for a distribution
system operator participating in an energy flexibility market.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fusco_F/0/1/0/all/0/1&quot;&gt;Francesco Fusco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eck_B/0/1/0/all/0/1&quot;&gt;Bradley Eck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gormally_R/0/1/0/all/0/1&quot;&gt;Robert Gormally&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Purcell_M/0/1/0/all/0/1&quot;&gt;Mark Purcell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tirupathi_S/0/1/0/all/0/1&quot;&gt;Seshu Tirupathi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07262">
<title>Robust and generalizable embryo selection based on artificial intelligence and time-lapse image sequences. (arXiv:2103.07262v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07262</link>
<description rdf:parseType="Literal">&lt;p&gt;Assessing and selecting the most viable embryos for transfer is an essential
part of in vitro fertilization (IVF). In recent years, several approaches have
been made to improve and automate the procedure using artificial intelligence
(AI) and deep learning. Based on images of embryos with known implantation data
(KID), AI models have been trained to automatically score embryos related to
their chance of achieving a successful implantation. However, as of now, only
limited research has been conducted to evaluate how embryo selection models
generalize to new clinics and how they perform in subgroup analyses across
various conditions. In this paper, we investigate how a deep learning-based
embryo selection model using only time-lapse image sequences performs across
different patient ages and clinical conditions, and how it correlates with
traditional morphokinetic parameters. The model was trained and evaluated based
on a large dataset from 18 IVF centers consisting of 115,832 embryos, of which
14,644 embryos were transferred KID embryos. In an independent test set, the AI
model sorted KID embryos with an area under the curve (AUC) of a receiver
operating characteristic curve of 0.67 and all embryos with an AUC of 0.95. A
clinic hold-out test showed that the model generalized to new clinics with an
AUC range of 0.60-0.75 for KID embryos. Across different subgroups of age,
insemination method, incubation time, and transfer protocol, the AUC ranged
between 0.63 and 0.69. Furthermore, model predictions correlated positively
with blastocyst grading and negatively with direct cleavages. The fully
automated iDAScore v1.0 model was shown to perform at least as good as a
state-of-the-art manual embryo selection model. Moreover, full automatization
of embryo scoring implies fewer manual evaluations and eliminates biases due to
inter- and intraobserver variation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berntsen_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf8;rgen Berntsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rimestad_J/0/1/0/all/0/1&quot;&gt;Jens Rimestad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lassen_J/0/1/0/all/0/1&quot;&gt;Jacob Theilgaard Lassen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_D/0/1/0/all/0/1&quot;&gt;Dang Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kragh_M/0/1/0/all/0/1&quot;&gt;Mikkel Fly Kragh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07268">
<title>Adversarial Machine Learning Security Problems for 6G: mmWave Beam Prediction Use-Case. (arXiv:2103.07268v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07268</link>
<description rdf:parseType="Literal">&lt;p&gt;6G is the next generation for the communication systems. In recent years,
machine learning algorithms have been applied widely in various fields such as
health, transportation, and the autonomous car. The predictive algorithms will
be used in 6G problems. With the rapid developments of deep learning
techniques, it is critical to take the security concern into account to apply
the algorithms. While machine learning offers significant advantages for 6G, AI
models&apos; security is ignored. Since it has many applications in the real world,
security is a vital part of the algorithms. This paper has proposed a
mitigation method for adversarial attacks against proposed 6G machine learning
models for the millimeter-wave (mmWave) beam prediction with adversarial
learning. The main idea behind adversarial attacks against machine learning
models is to produce faulty results by manipulating trained deep learning
models for 6G applications for mmWave beam prediction use case. We have also
presented the adversarial learning mitigation method&apos;s performance for 6G
security in millimeter-wave beam prediction application with fast gradient sign
method attack. The mean square errors of the defended model and undefended
model are very close.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Catak_E/0/1/0/all/0/1&quot;&gt;Evren Catak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Catak_F/0/1/0/all/0/1&quot;&gt;Ferhat Ozgur Catak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moldsvor_A/0/1/0/all/0/1&quot;&gt;Arild Moldsvor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07276">
<title>Modelling Animal Biodiversity Using Acoustic Monitoring and Deep Learning. (arXiv:2103.07276v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2103.07276</link>
<description rdf:parseType="Literal">&lt;p&gt;For centuries researchers have used sound to monitor and study wildlife.
Traditionally, conservationists have identified species by ear; however, it is
now common to deploy audio recording technology to monitor animal and ecosystem
sounds. Animals use sound for communication, mating, navigation and territorial
defence. Animal sounds provide valuable information and help conservationists
to quantify biodiversity. Acoustic monitoring has grown in popularity due to
the availability of diverse sensor types which include camera traps, portable
acoustic sensors, passive acoustic sensors, and even smartphones. Passive
acoustic sensors are easy to deploy and can be left running for long durations
to provide insights on habitat and the sounds made by animals and illegal
activity. While this technology brings enormous benefits, the amount of data
that is generated makes processing a time-consuming process for
conservationists. Consequently, there is interest among conservationists to
automatically process acoustic data to help speed up biodiversity assessments.
Processing these large data sources and extracting relevant sounds from
background noise introduces significant challenges. In this paper we outline an
approach for achieving this using state of the art in machine learning to
automatically extract features from time-series audio signals and modelling
deep learning models to classify different bird species based on the sounds
they make. The acquired bird songs are processed using mel-frequency cepstrum
(MFC) to extract features which are later classified using a multilayer
perceptron (MLP). Our proposed method achieved promising results with 0.74
sensitivity, 0.92 specificity and an accuracy of 0.74.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chalmers_C/0/1/0/all/0/1&quot;&gt;C. Chalmers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fergus_P/0/1/0/all/0/1&quot;&gt;P.Fergus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wich_S/0/1/0/all/0/1&quot;&gt;S. Wich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Longmore_S/0/1/0/all/0/1&quot;&gt;S. N. Longmore&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07279">
<title>Patient-specific virtual spine straightening and vertebra inpainting: An automatic framework for osteoplasty planning. (arXiv:2103.07279v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07279</link>
<description rdf:parseType="Literal">&lt;p&gt;Symptomatic spinal vertebral compression fractures (VCFs) often require
osteoplasty treatment. A cement-like material is injected into the bone to
stabilize the fracture, restore the vertebral body height and alleviate pain.
Leakage is a common complication and may occur due to too much cement being
injected. In this work, we propose an automated patient-specific framework that
can allow physicians to calculate an upper bound of cement for the injection
and estimate the optimal outcome of osteoplasty. The framework uses the patient
CT scan and the fractured vertebra label to build a virtual healthy spine using
a high-level approach. Firstly, the fractured spine is segmented with a
three-step Convolution Neural Network (CNN) architecture. Next, a per-vertebra
rigid registration to a healthy spine atlas restores its curvature. Finally, a
GAN-based inpainting approach replaces the fractured vertebra with an
estimation of its original shape. Based on this outcome, we then estimate the
maximum amount of bone cement for injection. We evaluate our framework by
comparing the virtual vertebrae volumes of ten patients to their healthy
equivalent and report an average error of 3.88$\pm$7.63\%. The presented
pipeline offers a first approach to a personalized automatic high-level
framework for planning osteoplasty procedures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bukas_C/0/1/0/all/0/1&quot;&gt;Christina Bukas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jian_B/0/1/0/all/0/1&quot;&gt;Bailiang Jian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venegas_L/0/1/0/all/0/1&quot;&gt;Luis F. Rodriguez Venegas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benetti_F/0/1/0/all/0/1&quot;&gt;Francesca De Benetti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruehling_S/0/1/0/all/0/1&quot;&gt;Sebastian Ruehling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sekubojina_A/0/1/0/all/0/1&quot;&gt;Anjany Sekubojina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gempt_J/0/1/0/all/0/1&quot;&gt;Jens Gempt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kirschke_J/0/1/0/all/0/1&quot;&gt;Jan S. Kirschke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piraud_M/0/1/0/all/0/1&quot;&gt;Marie Piraud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oberreuter_J/0/1/0/all/0/1&quot;&gt;Johannes Oberreuter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Navab_N/0/1/0/all/0/1&quot;&gt;Nassir Navab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wendler_T/0/1/0/all/0/1&quot;&gt;Thomas Wendler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07281">
<title>Empirical Mode Modeling: A data-driven approach to recover and forecast nonlinear dynamics from noisy data. (arXiv:2103.07281v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2103.07281</link>
<description rdf:parseType="Literal">&lt;p&gt;Data-driven, model-free analytics are natural choices for discovery and
forecasting of complex, nonlinear systems. Methods that operate in the system
state-space require either an explicit multidimensional state-space, or, one
approximated from available observations. Since observational data are
frequently sampled with noise, it is possible that noise can corrupt the
state-space representation degrading analytical performance. Here, we evaluate
the synthesis of empirical mode decomposition with empirical dynamic modeling,
which we term empirical mode modeling, to increase the information content of
state-space representations in the presence of noise. Evaluation of a
mathematical, and, an ecologically important geophysical application across
three different state-space representations suggests that empirical mode
modeling may be a useful technique for data-driven, model-free, state-space
analysis in the presence of noise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Park_J/0/1/0/all/0/1&quot;&gt;Joseph Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pao_G/0/1/0/all/0/1&quot;&gt;Gerald M Pao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stabenau_E/0/1/0/all/0/1&quot;&gt;Erik Stabenau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sugihara_G/0/1/0/all/0/1&quot;&gt;George Sugihara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lorimer_T/0/1/0/all/0/1&quot;&gt;Thomas Lorimer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07286">
<title>Integration of Convolutional Neural Networks in Mobile Applications. (arXiv:2103.07286v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07286</link>
<description rdf:parseType="Literal">&lt;p&gt;When building Deep Learning (DL) models, data scientists and software
engineers manage the trade-off between their accuracy, or any other suitable
success criteria, and their complexity. In an environment with high
computational power, a common practice is making the models go deeper by
designing more sophisticated architectures. However, in the context of mobile
devices, which possess less computational power, keeping complexity under
control is a must. In this paper, we study the performance of a system that
integrates a DL model as a trade-off between the accuracy and the complexity.
At the same time, we relate the complexity to the efficiency of the system.
With this, we present a practical study that aims to explore the challenges met
when optimizing the performance of DL models becomes a requirement. Concretely,
we aim to identify: (i) the most concerning challenges when deploying DL-based
software in mobile applications; and (ii) the path for optimizing the
performance trade-off. We obtain results that verify many of the identified
challenges in the related work such as the availability of frameworks and the
software-data dependency. We provide a documentation of our experience when
facing the identified challenges together with the discussion of possible
solutions to them. Additionally, we implement a solution to the sustainability
of the DL models when deployed in order to reduce the severity of other
identified challenges. Moreover, we relate the performance trade-off to a new
defined challenge featuring the impact of the complexity in the obtained
accuracy. Finally, we discuss and motivate future work that aims to provide
solutions to the more open challenges found.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castanyer_R/0/1/0/all/0/1&quot;&gt;Roger Creus Castanyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martinez_Fernandez_S/0/1/0/all/0/1&quot;&gt;Silverio Mart&amp;#xed;nez-Fern&amp;#xe1;ndez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franch_X/0/1/0/all/0/1&quot;&gt;Xavier Franch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07287">
<title>Neural Networks with Complex-Valued Weights Have No Spurious Local Minima. (arXiv:2103.07287v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07287</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the benefits of complex-valued weights for neural networks. We prove
that shallow complex neural networks with quadratic activations have no
spurious local minima. In contrast, shallow real neural networks with quadratic
activations have infinitely many spurious local minima under the same
conditions. In addition, we provide specific examples to demonstrate that
complex-valued weights turn poor local minima into saddle points. The
activation function CReLU is also discussed to illustrate the superiority of
analytic activations in complex-valued neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xingtu Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07292">
<title>VDSM: Unsupervised Video Disentanglement with State-Space Modeling and Deep Mixtures of Experts. (arXiv:2103.07292v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2103.07292</link>
<description rdf:parseType="Literal">&lt;p&gt;Disentangled representations support a range of downstream tasks including
causal reasoning, generative modeling, and fair machine learning.
Unfortunately, disentanglement has been shown to be impossible without the
incorporation of supervision or inductive bias. Given that supervision is often
expensive or infeasible to acquire, we choose to incorporate structural
inductive bias and present an unsupervised, deep State-Space-Model for Video
Disentanglement (VDSM). The model disentangles latent time-varying and dynamic
factors via the incorporation of hierarchical structure with a dynamic prior
and a Mixture of Experts decoder. VDSM learns separate disentangled
representations for the identity of the object or person in the video, and for
the action being performed. We evaluate VDSM across a range of qualitative and
quantitative tasks including identity and dynamics transfer, sequence
generation, Fr\&apos;echet Inception Distance, and factor classification. VDSM
provides state-of-the-art performance and exceeds adversarial methods, even
when the methods use additional supervision.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vowels_M/0/1/0/all/0/1&quot;&gt;Matthew J. Vowels&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Camgoz_N/0/1/0/all/0/1&quot;&gt;Necati Cihan Camgoz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bowden_R/0/1/0/all/0/1&quot;&gt;Richard Bowden&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07295">
<title>Adversarial Graph Disentanglement. (arXiv:2103.07295v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07295</link>
<description rdf:parseType="Literal">&lt;p&gt;A real-world graph has a complex topology structure, which is often formed by
the interaction of different latent factors. Disentanglement of these latent
factors can effectively improve the robustness and interpretability of node
representation of the graph. However, most existing methods lack consideration
of the intrinsic differences in links caused by factor entanglement. In this
paper, we propose an Adversarial Disentangled Graph Convolutional Network
(ADGCN) for disentangled graph representation learning. Specifically, a dynamic
multi-component convolution layer is designed to achieve micro-disentanglement
by inferring latent components that caused links between nodes. On the basis of
micro-disentanglement, we further propose a macro-disentanglement adversarial
regularizer that improves the separability between component distributions,
thus restricting interdependence among components. Additionally, to learn
collaboratively a better disentangled representation and topological structure,
a diversity preserving node sampling-based progressive refinement of graph
structure is proposed. The experimental results on various real-world graph
data verify that our ADGCN obtains remarkably more favorable performance over
currently available alternatives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1&quot;&gt;Shuai Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhenfeng Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhizhe Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1&quot;&gt;Shuiwang Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yao Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07297">
<title>Automating the GDPR Compliance Assessment for Cross-border Personal Data Transfers in Android Applications. (arXiv:2103.07297v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2103.07297</link>
<description rdf:parseType="Literal">&lt;p&gt;The General Data Protection Regulation (GDPR) aims to ensure that all
personal data processing activities are fair and transparent for the European
Union (EU) citizens, regardless of whether these are carried out within the EU
or anywhere else. To this end, it sets strict requirements to transfer personal
data outside the EU. However, checking these requirements is a daunting task
for supervisory authorities, particularly in the mobile app domain due to the
huge number of apps available and their dynamic nature. In this paper, we
propose a fully automated method to assess the compliance of mobile apps with
the GDPR requirements for cross-border personal data transfers. We have applied
the method to the top-free 10,080 apps from the Google Play Store. The results
reveal that there is still a very significant gap between what app providers
and third-party recipients do in practice and what is intended by the GDPR. A
substantial 56% of analysed apps are potentially non-compliant with the GDPR
cross-border transfer requirements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guaman_D/0/1/0/all/0/1&quot;&gt;Danny S. Guam&amp;#xe1;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferrer_X/0/1/0/all/0/1&quot;&gt;Xavier Ferrer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alamo_J/0/1/0/all/0/1&quot;&gt;Jose M. del Alamo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Such_J/0/1/0/all/0/1&quot;&gt;Jose Such&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07303">
<title>Second-Order Component Analysis for Fault Detection. (arXiv:2103.07303v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07303</link>
<description rdf:parseType="Literal">&lt;p&gt;Process monitoring based on neural networks is getting more and more
attention. Compared with classical neural networks, high-order neural networks
have natural advantages in dealing with heteroscedastic data. However,
high-order neural networks might bring the risk of overfitting and learning
both the key information from original data and noises or anomalies. Orthogonal
constraints can greatly reduce correlations between extracted features, thereby
reducing the overfitting risk. This paper proposes a novel fault detection
method called second-order component analysis (SCA). SCA rules out the
heteroscedasticity of pro-cess data by optimizing a second-order autoencoder
with orthogonal constraints. In order to deal with this constrained
optimization problem, a geometric conjugate gradient algorithm is adopted in
this paper, which performs geometric optimization on the combination of Stiefel
manifold and Euclidean manifold. Extensive experiments on the Tennessee-Eastman
benchmark pro-cess show that SCA outperforms PCA, KPCA, and autoencoder in
missed detection rate (MDR) and false alarm rate (FAR).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jingchao_P/0/1/0/all/0/1&quot;&gt;Peng Jingchao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haitao_Z/0/1/0/all/0/1&quot;&gt;Zhao Haitao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhengwei_H/0/1/0/all/0/1&quot;&gt;Hu Zhengwei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07350">
<title>Self-Feature Regularization: Self-Feature Distillation Without Teacher Models. (arXiv:2103.07350v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07350</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge distillation is the process of transferring the knowledge from a
large model to a small model. In this process, the small model learns the
generalization ability of the large model and retains the performance close to
that of the large model. Knowledge distillation provides a training means to
migrate the knowledge of models, facilitating model deployment and speeding up
inference. However, previous distillation methods require pre-trained teacher
models, which still bring computational and storage overheads. In this paper, a
novel general training framework called Self-Feature Regularization~(SFR) is
proposed, which uses features in the deep layers to supervise feature learning
in the shallow layers, retains more semantic information. Specifically, we
firstly use EMD-l2 loss to match local features and a many-to-one approach to
distill features more intensively in the channel dimension. Then dynamic label
smoothing is used in the output layer to achieve better performance.
Experiments further show the effectiveness of our proposed framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1&quot;&gt;Wenxuan Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1&quot;&gt;Zhenyan Hou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07364">
<title>Game-theoretic Understanding of Adversarially Learned Features. (arXiv:2103.07364v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07364</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper aims to understand adversarial attacks and defense from a new
perspecitve, i.e., the signal-processing behavior of DNNs. We novelly define
the multi-order interaction in game theory, which satisfies six properties.
With the multi-order interaction, we discover that adversarial attacks mainly
affect high-order interactions to fool the DNN. Furthermore, we find that the
robustness of adversarially trained DNNs comes from category-specific low-order
interactions. Our findings provide more insights into and make a revision of
previous understanding for the shape bias of adversarially learned features.
Besides, the multi-order interaction can also explain the recoverability of
adversarial examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1&quot;&gt;Jie Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Die Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yisen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhanpeng Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1&quot;&gt;Xu Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiting Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jie Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Quanshi Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07388">
<title>A Neural Network for Semigroups. (arXiv:2103.07388v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07388</link>
<description rdf:parseType="Literal">&lt;p&gt;Tasks like image reconstruction in computer vision, matrix completion in
recommender systems and link prediction in graph theory, are well studied in
machine learning literature. In this work, we apply a denoising
autoencoder-based neural network architecture to the task of completing partial
multiplication (Cayley) tables of finite semigroups. We suggest a novel loss
function for that task based on the algebraic nature of the semigroup data. We
also provide a software package for conducting experiments similar to those
carried out in this work. Our experiments showed that with only about 10% of
the available data, it is possible to build a model capable of reconstructing a
full Cayley from only half of it in about 80% of cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balzin_E/0/1/0/all/0/1&quot;&gt;Edouard Balzin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shminke_B/0/1/0/all/0/1&quot;&gt;Boris Shminke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07405">
<title>Optimal sequential decision making with probabilistic digital twins. (arXiv:2103.07405v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2103.07405</link>
<description rdf:parseType="Literal">&lt;p&gt;Digital twins are emerging in many industries, typically consisting of
simulation models and data associated with a specific physical system. One of
the main reasons for developing a digital twin, is to enable the simulation of
possible consequences of a given action, without the need to interfere with the
physical system itself. Physical systems of interest, and the environments they
operate in, do not always behave deterministically. Moreover, information about
the system and its environment is typically incomplete or imperfect.
Probabilistic representations of systems and environments may therefore be
called for, especially to support decisions in application areas where actions
may have severe consequences.
&lt;/p&gt;
&lt;p&gt;In this paper we introduce the probabilistic digital twin (PDT). We will
start by discussing how epistemic uncertainty can be treated using measure
theory, by modelling epistemic information via $\sigma$-algebras. Based on
this, we give a formal definition of how epistemic uncertainty can be updated
in a PDT. We then study the problem of optimal sequential decision making. That
is, we consider the case where the outcome of each decision may inform the
next. Within the PDT framework, we formulate this optimization problem. We
discuss how this problem may be solved (at least in theory) via the maximum
principle method or the dynamic programming principle. However, due to the
curse of dimensionality, these methods are often not tractable in practice. To
mend this, we propose a generic approximate solution using deep reinforcement
learning together with neural networks defined on sets. We illustrate the
method on a practical problem, considering optimal information gathering for
the estimation of a failure probability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Agrell_C/0/1/0/all/0/1&quot;&gt;Christian Agrell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dahl_K/0/1/0/all/0/1&quot;&gt;Kristina Rognlien Dahl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hafver_A/0/1/0/all/0/1&quot;&gt;Andreas Hafver&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07423">
<title>Radiomic Deformation and Textural Heterogeneity (R-DepTH) Descriptor to characterize Tumor Field Effect: Application to Survival Prediction in Glioblastoma. (arXiv:2103.07423v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2103.07423</link>
<description rdf:parseType="Literal">&lt;p&gt;The concept of tumor field effect implies that cancer is a systemic disease
with its impact way beyond the visible tumor confines. For instance, in
Glioblastoma (GBM), an aggressive brain tumor, the increase in intracranial
pressure due to tumor burden often leads to brain herniation and poor outcomes.
Our work is based on the rationale that highly aggressive tumors tend to grow
uncontrollably, leading to pronounced biomechanical tissue deformations in the
normal parenchyma, which when combined with local morphological differences in
the tumor confines on MRI scans, will comprehensively capture tumor field
effect. Specifically, we present an integrated MRI-based descriptor,
radiomic-Deformation and Textural Heterogeneity (r-DepTH). This descriptor
comprises measurements of the subtle perturbations in tissue deformations
throughout the surrounding normal parenchyma due to mass effect. This involves
non-rigidly aligning the patients MRI scans to a healthy atlas via
diffeomorphic registration. The resulting inverse mapping is used to obtain the
deformation field magnitudes in the normal parenchyma. These measurements are
then combined with a 3D texture descriptor, Co-occurrence of Local Anisotropic
Gradient Orientations (COLLAGE), which captures the morphological heterogeneity
within the tumor confines, on MRI scans. R-DepTH, on N = 207 GBM cases
(training set (St) = 128, testing set (Sv) = 79), demonstrated improved
prognosis of overall survival by categorizing patients into low- (prolonged
survival) and high-risk (poor survival) groups (on St, p-value = 0.0000035, and
on Sv, p-value = 0.0024). R-DepTH descriptor may serve as a comprehensive
MRI-based prognostic marker of disease aggressiveness and survival in solid
tumors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ismail_M/0/1/0/all/0/1&quot;&gt;Marwa Ismail&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Prasanna_P/0/1/0/all/0/1&quot;&gt;Prateek Prasanna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bera_K/0/1/0/all/0/1&quot;&gt;Kaustav Bera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Statsevych_V/0/1/0/all/0/1&quot;&gt;Volodymyr Statsevych&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hill_V/0/1/0/all/0/1&quot;&gt;Virginia Hill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Singh_G/0/1/0/all/0/1&quot;&gt;Gagandeep Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Partovi_S/0/1/0/all/0/1&quot;&gt;Sasan Partovi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Beig_N/0/1/0/all/0/1&quot;&gt;Niha Beig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+McGarry_S/0/1/0/all/0/1&quot;&gt;Sean McGarry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Laviolette_P/0/1/0/all/0/1&quot;&gt;Peter Laviolette&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ahluwalia_M/0/1/0/all/0/1&quot;&gt;Manmeet Ahluwalia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Madabhushi_A/0/1/0/all/0/1&quot;&gt;Anant Madabhushi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tiwari_P/0/1/0/all/0/1&quot;&gt;Pallavi Tiwari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07445">
<title>Efficient reconstruction of depth three circuits with top fan-in two. (arXiv:2103.07445v1 [cs.CC])</title>
<link>http://arxiv.org/abs/2103.07445</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop efficient randomized algorithms to solve the black-box
reconstruction problem for polynomials over finite fields, computable by depth
three arithmetic circuits with alternating addition/multiplication gates, such
that output gate is an addition gate with in-degree two. These circuits compute
polynomials of form $G\times(T_1 + T_2)$, where $G,T_1,T_2$ are product of
affine forms, and polynomials $T_1,T_2$ have no common factors. Rank of such a
circuit is defined as dimension of vector space spanned by all affine factors
of $T_1$ and $T_2$. For any polynomial $f$ computable by such a circuit,
$rank(f)$ is defined to be the minimum rank of any such circuit computing it.
Our work develops randomized reconstruction algorithms which take as input
black-box access to a polynomial $f$ (over finite field $\mathbb{F}$),
computable by such a circuit. Here are the results.
&lt;/p&gt;
&lt;p&gt;1 [Low rank]: When $5\leq rank(f) = O(\log^3 d)$, it runs in time
$(nd^{\log^3d}\log |\mathbb{F}|)^{O(1)}$, and, with high probability, outputs a
depth three circuit computing $f$, with top addition gate having in-degree
$\leq d^{rank(f)}$.
&lt;/p&gt;
&lt;p&gt;2 [High rank]: When $rank(f) = \Omega(\log^3 d)$, it runs in time $(nd\log
|\mathbb{F}|)^{O(1)}$, and, with high probability, outputs a depth three
circuit computing $f$, with top addition gate having in-degree two.
&lt;/p&gt;
&lt;p&gt;Ours is the first blackbox reconstruction algorithm for this circuit class,
that runs in time polynomial in $\log |\mathbb{F}|$. This problem has been
mentioned as an open problem in [GKL12] (STOC 2012)
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinha_G/0/1/0/all/0/1&quot;&gt;Gaurav Sinha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07453">
<title>Machine Learning Assisted Orthonormal Basis Selection for Functional Data Analysis. (arXiv:2103.07453v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2103.07453</link>
<description rdf:parseType="Literal">&lt;p&gt;In implementations of the functional data methods, the effect of the initial
choice of an orthonormal basis has not gained much attention in the past.
Typically, several standard bases such as Fourier, wavelets, splines, etc. are
considered to transform observed functional data and a choice is made without
any formal criteria indicating which of the bases is preferable for the initial
transformation of the data into functions. In an attempt to address this issue,
we propose a strictly data-driven method of orthogonal basis selection. The
method uses recently introduced orthogonal spline bases called the splinets
obtained by efficient orthogonalization of the B-splines. The algorithm learns
from the data in the machine learning style to efficiently place knots. The
optimality criterion is based on the average (per functional data point) mean
square error and is utilized both in the learning algorithms and in comparison
studies. The latter indicates efficiency that is particularly evident for the
sparse functional data and to a lesser degree in analyses of responses to
complex physical systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Basna_R/0/1/0/all/0/1&quot;&gt;Rani Basna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nassar_H/0/1/0/all/0/1&quot;&gt;Hiba Nassar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Podgorski_K/0/1/0/all/0/1&quot;&gt;Krzysztof Podg&amp;#xf3;rski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07454">
<title>EventGraD: Event-Triggered Communication in Parallel Machine Learning. (arXiv:2103.07454v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2103.07454</link>
<description rdf:parseType="Literal">&lt;p&gt;Communication in parallel systems imposes significant overhead which often
turns out to be a bottleneck in parallel machine learning. To relieve some of
this overhead, in this paper, we present EventGraD - an algorithm with
event-triggered communication for stochastic gradient descent in parallel
machine learning. The main idea of this algorithm is to modify the requirement
of communication at every iteration in standard implementations of stochastic
gradient descent in parallel machine learning to communicating only when
necessary at certain iterations. We provide theoretical analysis of convergence
of our proposed algorithm. We also implement the proposed algorithm for
data-parallel training of a popular residual neural network used for training
the CIFAR-10 dataset and show that EventGraD can reduce the communication load
by up to 60% while retaining the same level of accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Soumyadip Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aquino_B/0/1/0/all/0/1&quot;&gt;Bernardo Aquino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1&quot;&gt;Vijay Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.07458">
<title>Multiview Sensing With Unknown Permutations: An Optimal Transport Approach. (arXiv:2103.07458v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2103.07458</link>
<description rdf:parseType="Literal">&lt;p&gt;In several applications, including imaging of deformable objects while in
motion, simultaneous localization and mapping, and unlabeled sensing, we
encounter the problem of recovering a signal that is measured subject to
unknown permutations. In this paper we take a fresh look at this problem
through the lens of optimal transport (OT). In particular, we recognize that in
most practical applications the unknown permutations are not arbitrary but some
are more likely to occur than others. We exploit this by introducing a
regularization function that promotes the more likely permutations in the
solution. We show that, even though the general problem is not convex, an
appropriate relaxation of the resulting regularized problem allows us to
exploit the well-developed machinery of OT and develop a tractable algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1&quot;&gt;Yanting Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boufounos_P/0/1/0/all/0/1&quot;&gt;Petros T. Boufounos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mansour_H/0/1/0/all/0/1&quot;&gt;Hassan Mansour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aeron_S/0/1/0/all/0/1&quot;&gt;Shuchin Aeron&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06942">
<title>PACO: Global Signal Restoration via PAtch COnsensus. (arXiv:1808.06942v3 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/1808.06942</link>
<description rdf:parseType="Literal">&lt;p&gt;Many signal processing algorithms break the target signal into overlapping
segments (also called windows, or patches), process them separately, and then
stitch them back into place to produce a unified output. At the overlaps, the
final value of those samples that are estimated more than once needs to be
decided in some way. Averaging, the simplest approach, often leads to
unsatisfactory results. Significant work has been devoted to this issue in
recent years. Several works explore the idea of a weighted average of the
overlapped patches and/or pixels; others promote agreement (consensus) between
the patches at their intersections. Agreement can be either encouraged or
imposed as a hard constraint. This work develops on the latter case. The result
is a variational signal processing framework, named PACO, which features a
number of appealing theoretical and practical properties. The PACO framework
consists of a variational formulation that fits a wide variety of problems, and
a general ADMMbased algorithm for minimizing the resulting energies. As a
byproduct, we show that the consensus step of the algorithm, which is the main
bottleneck of similar methods, can be solved efficiently and easily for any
arbitrary patch decomposition scheme. We demonstrate the flexibility and power
of PACO on three different problems: image inpainting (which we have already
covered in previous works), image denoising, and contrast enhancement, using
different cost functions including Laplacian and Gaussian Mixture Models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Paulino_I/0/1/0/all/0/1&quot;&gt;Ignacio Francisco Ram&amp;#xed;rez Paulino&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.02220">
<title>Deep Neural Network Approximation Theory. (arXiv:1901.02220v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1901.02220</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper develops fundamental limits of deep neural network learning by
characterizing what is possible if no constraints are imposed on the learning
algorithm and on the amount of training data. Concretely, we consider
Kolmogorov-optimal approximation through deep neural networks with the guiding
theme being a relation between the complexity of the function (class) to be
approximated and the complexity of the approximating network in terms of
connectivity and memory requirements for storing the network topology and the
associated quantized weights. The theory we develop establishes that deep
networks are Kolmogorov-optimal approximants for markedly different function
classes, such as unit balls in Besov spaces and modulation spaces. In addition,
deep networks provide exponential approximation accuracy - i.e., the
approximation error decays exponentially in the number of nonzero weights in
the network - of the multiplication operation, polynomials, sinusoidal
functions, and certain smooth functions. Moreover, this holds true even for
one-dimensional oscillatory textures and the Weierstrass function - a fractal
function, neither of which has previously known methods achieving exponential
approximation accuracy. We also show that in the approximation of sufficiently
smooth functions finite-width deep networks require strictly smaller
connectivity than finite-depth wide networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elbrachter_D/0/1/0/all/0/1&quot;&gt;Dennis Elbr&amp;#xe4;chter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perekrestenko_D/0/1/0/all/0/1&quot;&gt;Dmytro Perekrestenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grohs_P/0/1/0/all/0/1&quot;&gt;Philipp Grohs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bolcskei_H/0/1/0/all/0/1&quot;&gt;Helmut B&amp;#xf6;lcskei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1906.02325">
<title>Privacy-Preserving Classification of Personal Text Messages with Secure Multi-Party Computation: An Application to Hate-Speech Detection. (arXiv:1906.02325v3 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1906.02325</link>
<description rdf:parseType="Literal">&lt;p&gt;Classification of personal text messages has many useful applications in
surveillance, e-commerce, and mental health care, to name a few. Giving
applications access to personal texts can easily lead to (un)intentional
privacy violations. We propose the first privacy-preserving solution for text
classification that is provably secure. Our method, which is based on Secure
Multiparty Computation (SMC), encompasses both feature extraction from texts,
and subsequent classification with logistic regression and tree ensembles. We
prove that when using our secure text classification method, the application
does not learn anything about the text, and the author of the text does not
learn anything about the text classification model used by the application
beyond what is given by the classification result itself. We perform end-to-end
experiments with an application for detecting hate speech against women and
immigrants, demonstrating excellent runtime results without loss of accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reich_D/0/1/0/all/0/1&quot;&gt;Devin Reich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Todoki_A/0/1/0/all/0/1&quot;&gt;Ariel Todoki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dowsley_R/0/1/0/all/0/1&quot;&gt;Rafael Dowsley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cock_M/0/1/0/all/0/1&quot;&gt;Martine De Cock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nascimento_A/0/1/0/all/0/1&quot;&gt;Anderson C. A. Nascimento&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1910.03471">
<title>Identifying nonlinear dynamical systems with multiple time scales and long-range dependencies. (arXiv:1910.03471v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1910.03471</link>
<description rdf:parseType="Literal">&lt;p&gt;A main theoretical interest in biology and physics is to identify the
nonlinear dynamical system (DS) that generated observed time series. Recurrent
Neural Networks (RNNs) are, in principle, powerful enough to approximate any
underlying DS, but in their vanilla form suffer from the exploding vs.
vanishing gradients problem. Previous attempts to alleviate this problem
resulted either in more complicated, mathematically less tractable RNN
architectures, or strongly limited the dynamical expressiveness of the RNN.
Here we address this issue by suggesting a simple regularization scheme for
vanilla RNNs with ReLU activation which enables them to solve long-range
dependency problems and express slow time scales, while retaining a simple
mathematical structure which makes their DS properties partly analytically
accessible. We prove two theorems that establish a tight connection between the
regularized RNN dynamics and its gradients, illustrate on DS benchmarks that
our regularization approach strongly eases the reconstruction of DS which
harbor widely differing time scales, and show that our method is also en par
with other long-range architectures like LSTMs on several tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_D/0/1/0/all/0/1&quot;&gt;Dominik Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koppe_G/0/1/0/all/0/1&quot;&gt;Georgia Koppe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monfared_Z/0/1/0/all/0/1&quot;&gt;Zahra Monfared&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beutelspacher_M/0/1/0/all/0/1&quot;&gt;Max Beutelspacher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Durstewitz_D/0/1/0/all/0/1&quot;&gt;Daniel Durstewitz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1911.09721">
<title>Communication-Efficient and Byzantine-Robust Distributed Learning with Error Feedback. (arXiv:1911.09721v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1911.09721</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a communication-efficient distributed learning algorithm that is
robust against Byzantine worker machines. We propose and analyze a distributed
gradient-descent algorithm that performs a simple thresholding based on
gradient norms to mitigate Byzantine failures. We show the (statistical)
error-rate of our algorithm matches that of Yin et al.~\cite{dong}, which uses
more complicated schemes (coordinate-wise median, trimmed mean). Furthermore,
for communication efficiency, we consider a generic class of
$\delta$-approximate compressors from Karimireddi et al.~\cite{errorfeed} that
encompasses sign-based compressors and top-$k$ sparsification. Our algorithm
uses compressed gradients and gradient norms for aggregation and Byzantine
removal respectively. We establish the statistical error rate for non-convex
smooth loss functions. We show that, in certain range of the compression factor
$\delta$, the (order-wise) rate of convergence is not affected by the
compression operation. Moreover, we analyze the compressed gradient descent
algorithm with error feedback (proposed in \cite{errorfeed}) in a distributed
setting and in the presence of Byzantine worker machines. We show that
exploiting error feedback improves the statistical error rate. Finally, we
experimentally validate our results and show good performance in convergence
for convex (least-square regression) and non-convex (neural network training)
problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1&quot;&gt;Avishek Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maity_R/0/1/0/all/0/1&quot;&gt;Raj Kumar Maity&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kadhe_S/0/1/0/all/0/1&quot;&gt;Swanand Kadhe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazumdar_A/0/1/0/all/0/1&quot;&gt;Arya Mazumdar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramchandran_K/0/1/0/all/0/1&quot;&gt;Kannan Ramchandran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1912.08881">
<title>Pruning by Explaining: A Novel Criterion for Deep Neural Network Pruning. (arXiv:1912.08881v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1912.08881</link>
<description rdf:parseType="Literal">&lt;p&gt;The success of convolutional neural networks (CNNs) in various applications
is accompanied by a significant increase in computation and parameter storage
costs. Recent efforts to reduce these overheads involve pruning and compressing
the weights of various layers while at the same time aiming to not sacrifice
performance. In this paper, we propose a novel criterion for CNN pruning
inspired by neural network interpretability: The most relevant units, i.e.
weights or filters, are automatically found using their relevance scores
obtained from concepts of explainable AI (XAI). By exploring this idea, we
connect the lines of interpretability and model compression research. We show
that our proposed method can efficiently prune CNN models in transfer-learning
setups in which networks pre-trained on large corpora are adapted to
specialized tasks. The method is evaluated on a broad range of computer vision
datasets. Notably, our novel criterion is not only competitive or better
compared to state-of-the-art pruning criteria when successive retraining is
performed, but clearly outperforms these previous criteria in the
resource-constrained application scenario in which the data of the task to be
transferred to is very scarce and one chooses to refrain from fine-tuning. Our
method is able to compress the model iteratively while maintaining or even
improving accuracy. At the same time, it has a computational cost in the order
of gradient computation and is comparatively simple to apply without the need
for tuning hyperparameters for pruning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeom_S/0/1/0/all/0/1&quot;&gt;Seul-Ki Yeom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seegerer_P/0/1/0/all/0/1&quot;&gt;Philipp Seegerer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lapuschkin_S/0/1/0/all/0/1&quot;&gt;Sebastian Lapuschkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Binder_A/0/1/0/all/0/1&quot;&gt;Alexander Binder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiedemann_S/0/1/0/all/0/1&quot;&gt;Simon Wiedemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muller_K/0/1/0/all/0/1&quot;&gt;Klaus-Robert M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samek_W/0/1/0/all/0/1&quot;&gt;Wojciech Samek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2001.05876">
<title>Show, Recall, and Tell: Image Captioning with Recall Mechanism. (arXiv:2001.05876v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2001.05876</link>
<description rdf:parseType="Literal">&lt;p&gt;Generating natural and accurate descriptions in image cap-tioning has always
been a challenge. In this paper, we pro-pose a novel recall mechanism to
imitate the way human con-duct captioning. There are three parts in our recall
mecha-nism : recall unit, semantic guide (SG) and recalled-wordslot (RWS).
Recall unit is a text-retrieval module designedto retrieve recalled words for
images. SG and RWS are de-signed for the best use of recalled words. SG branch
cangenerate a recalled context, which can guide the process ofgenerating
caption. RWS branch is responsible for copyingrecalled words to the caption.
Inspired by pointing mecha-nism in text summarization, we adopt a soft switch
to balancethe generated-word probabilities between SG and RWS. Inthe CIDEr
optimization step, we also introduce an individualrecalled-word reward (WR) to
boost training. Our proposedmethods (SG+RWS+WR) achieve BLEU-4 / CIDEr /
SPICEscores of 36.6 / 116.9 / 21.3 with cross-entropy loss and 38.7 /129.1 /
22.4 with CIDEr optimization on MSCOCO Karpathytest split, which surpass the
results of other state-of-the-artmethods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Li Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_Z/0/1/0/all/0/1&quot;&gt;Zechen Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yonghua Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1&quot;&gt;Hongtao Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2003.04774">
<title>ENTMOOT: A Framework for Optimization over Ensemble Tree Models. (arXiv:2003.04774v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2003.04774</link>
<description rdf:parseType="Literal">&lt;p&gt;Gradient boosted trees and other regression tree models perform well in a
wide range of real-world, industrial applications. These tree models (i) offer
insight into important prediction features, (ii) effectively manage sparse
data, and (iii) have excellent prediction capabilities. Despite their
advantages, they are generally unpopular for decision-making tasks and
black-box optimization, which is due to their difficult-to optimize structure
and the lack of a reliable uncertainty measure. ENTMOOT is our new framework
for integrating (already trained) tree models into larger optimization
problems. The contributions of ENTMOOT include: (i) explicitly introducing a
reliable uncertainty measure that is compatible with tree models, (ii) solving
the larger optimization problems that incorporate these uncertainty aware tree
models, (iii) proving that the solutions are globally optimal, i.e. no better
solution exists. In particular, we show how the ENTMOOT approach allows a
simple integration of tree models into decision-making and black-box
optimization, where it proves as a strong competitor to commonly-used
frameworks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thebelt_A/0/1/0/all/0/1&quot;&gt;Alexander Thebelt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kronqvist_J/0/1/0/all/0/1&quot;&gt;Jan Kronqvist&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mistry_M/0/1/0/all/0/1&quot;&gt;Miten Mistry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_R/0/1/0/all/0/1&quot;&gt;Robert M. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sudermann_Merx_N/0/1/0/all/0/1&quot;&gt;Nathan Sudermann-Merx&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Misener_R/0/1/0/all/0/1&quot;&gt;Ruth Misener&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2004.03734">
<title>Locality Preserving Loss: Neighbors that Live together, Align together. (arXiv:2004.03734v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2004.03734</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a locality preserving loss (LPL) that improves the alignment
between vector space embeddings while separating uncorrelated representations.
Given two pretrained embedding manifolds, LPL optimizes a model to project an
embedding and maintain its local neighborhood while aligning one manifold to
another. This reduces the overall size of the dataset required to align the two
in tasks such as cross-lingual word alignment. We show that the LPL-based
alignment between input vector spaces acts as a regularizer, leading to better
and consistent accuracy than the baseline, especially when the size of the
training set is small. We demonstrate the effectiveness of LPL optimized
alignment on semantic text similarity (STS), natural language inference (SNLI),
multi-genre language inference (MNLI) and cross-lingual word alignment(CLA)
showing consistent improvements, finding up to 16% improvement over our
baseline in lower resource settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganesan_A/0/1/0/all/0/1&quot;&gt;Ashwinkumar Ganesan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferraro_F/0/1/0/all/0/1&quot;&gt;Francis Ferraro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oates_T/0/1/0/all/0/1&quot;&gt;Tim Oates&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2005.12420">
<title>Network Bending: Expressive Manipulation of Deep Generative Models. (arXiv:2005.12420v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2005.12420</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new framework for manipulating and interacting with deep
generative models that we call network bending. We present a comprehensive set
of deterministic transformations that can be inserted as distinct layers into
the computational graph of a trained generative neural network and applied
during inference. In addition, we present a novel algorithm for analysing the
deep generative model and clustering features based on their spatial activation
maps. This allows features to be grouped together based on spatial similarity
in an unsupervised fashion. This results in the meaningful manipulation of sets
of features that correspond to the generation of a broad array of semantically
significant features of the generated images. We outline this framework,
demonstrating our results on state-of-the-art deep generative models trained on
several image datasets. We show how it allows for the direct manipulation of
semantically meaningful aspects of the generative process as well as allowing
for a broad range of expressive outcomes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Broad_T/0/1/0/all/0/1&quot;&gt;Terence Broad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leymarie_F/0/1/0/all/0/1&quot;&gt;Frederic Fol Leymarie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grierson_M/0/1/0/all/0/1&quot;&gt;Mick Grierson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2006.02479">
<title>Least $k$th-Order and R\&apos;{e}nyi Generative Adversarial Networks. (arXiv:2006.02479v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2006.02479</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the use of parametrized families of information-theoretic
measures to generalize the loss functions of generative adversarial networks
(GANs) with the objective of improving performance. A new generator loss
function, called least $k$th-order GAN (L$k$GAN), is first introduced,
generalizing the least squares GANs (LSGANs) by using a $k$th order absolute
error distortion measure with $k \geq 1$ (which recovers the LSGAN loss
function when $k=2$). It is shown that minimizing this generalized loss
function under an (unconstrained) optimal discriminator is equivalent to
minimizing the $k$th-order Pearson-Vajda divergence. Another novel GAN
generator loss function is next proposed in terms of R\&apos;{e}nyi cross-entropy
functionals with order $\alpha &amp;gt;0$, $\alpha\neq 1$. It is demonstrated that
this R\&apos;{e}nyi-centric generalized loss function, which provably reduces to the
original GAN loss function as $\alpha\to1$, preserves the equilibrium point
satisfied by the original GAN based on the Jensen-R\&apos;{e}nyi divergence, a
natural extension of the Jensen-Shannon divergence.
&lt;/p&gt;
&lt;p&gt;Experimental results indicate that the proposed loss functions, applied to
the MNIST and CelebA datasets, under both DCGAN and StyleGAN architectures,
confer performance benefits by virtue of the extra degrees of freedom provided
by the parameters $k$ and $\alpha$, respectively. More specifically,
experiments show improvements with regard to the quality of the generated
images as measured by the Fr\&apos;echet Inception Distance (FID) score and training
stability. While it was applied to GANs in this study, the proposed approach is
generic and can be used in other applications of information theory to deep
learning, e.g., the issues of fairness or privacy in artificial intelligence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhatia_H/0/1/0/all/0/1&quot;&gt;Himesh Bhatia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paul_W/0/1/0/all/0/1&quot;&gt;William Paul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alajaji_F/0/1/0/all/0/1&quot;&gt;Fady Alajaji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gharesifard_B/0/1/0/all/0/1&quot;&gt;Bahman Gharesifard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burlina_P/0/1/0/all/0/1&quot;&gt;Philippe Burlina&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2006.03031">
<title>Nimble: Efficiently Compiling Dynamic Neural Networks for Model Inference. (arXiv:2006.03031v2 [cs.PL] UPDATED)</title>
<link>http://arxiv.org/abs/2006.03031</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern deep neural networks increasingly make use of features such as dynamic
control flow, data structures and dynamic tensor shapes. Existing deep learning
systems focus on optimizing and executing static neural networks which assume a
pre-determined model architecture and input data shapes--assumptions which are
violated by dynamic neural networks. Therefore, executing dynamic models with
deep learning systems is currently both inflexible and sub-optimal, if not
impossible. Optimizing dynamic neural networks is more challenging than static
neural networks; optimizations must consider all possible execution paths and
tensor shapes. This paper proposes Nimble, a high-performance and flexible
system to optimize, compile, and execute dynamic neural networks on multiple
platforms. Nimble handles model dynamism by introducing a dynamic type system,
a set of dynamism-oriented optimizations, and a light-weight virtual machine
runtime. Our evaluation demonstrates that Nimble outperforms state-of-the-art
deep learning frameworks and runtime systems for dynamic neural networks by up
to 20x on hardware platforms including Intel CPUs, ARM CPUs, and Nvidia GPUs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1&quot;&gt;Haichen Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roesch_J/0/1/0/all/0/1&quot;&gt;Jared Roesch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yong Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Mu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_V/0/1/0/all/0/1&quot;&gt;Vin Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tatlock_Z/0/1/0/all/0/1&quot;&gt;Zachary Tatlock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yida Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2006.06983">
<title>Characterizing Impacts of Heterogeneity in Federated Learning upon Large-Scale Smartphone Data. (arXiv:2006.06983v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2006.06983</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) is an emerging, privacy-preserving machine learning
paradigm, drawing tremendous attention in both academia and industry. A unique
characteristic of FL is heterogeneity, which resides in the various hardware
specifications and dynamic states across the participating devices.
Theoretically, heterogeneity can exert a huge influence on the FL training
process, e.g., causing a device unavailable for training or unable to upload
its model updates. Unfortunately, these impacts have never been systematically
studied and quantified in existing FL literature.
&lt;/p&gt;
&lt;p&gt;In this paper, we carry out the first empirical study to characterize the
impacts of heterogeneity in FL. We collect large-scale data from 136k
smartphones that can faithfully reflect heterogeneity in real-world settings.
We also build a heterogeneity-aware FL platform that complies with the standard
FL protocol but with heterogeneity in consideration. Based on the data and the
platform, we conduct extensive experiments to compare the performance of
state-of-the-art FL algorithms under heterogeneity-aware and
heterogeneity-unaware settings. Results show that heterogeneity causes
non-trivial performance degradation in FL, including up to 9.2% accuracy drop,
2.32x lengthened training time, and undermined fairness. Furthermore, we
analyze potential impact factors and find that device failure and participant
bias are two potential factors for performance degradation. Our study provides
insightful implications for FL practitioners. On the one hand, our findings
suggest that FL algorithm designers consider necessary heterogeneity during the
evaluation. On the other hand, our findings urge system providers to design
specific mechanisms to mitigate the impacts of heterogeneity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chengxu Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qipeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1&quot;&gt;Mengwei Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhenpeng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bian_K/0/1/0/all/0/1&quot;&gt;Kaigui Bian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yunxin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xuanzhe Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2006.07701">
<title>Dynamic Feature Acquisition with Arbitrary Conditional Flows. (arXiv:2006.07701v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2006.07701</link>
<description rdf:parseType="Literal">&lt;p&gt;Many real-world situations allow for the acquisition of additional relevant
information when making an assessment with limited or uncertain data. However,
traditional ML approaches either require all features to be acquired beforehand
or regard part of them as missing data that cannot be acquired. In this work,
we propose models that dynamically acquire new features to further improve the
prediction assessment. To trade off the improvement with the cost of
acquisition, we leverage an information theoretic metric, conditional mutual
information, to select the most informative feature to acquire. We leverage a
generative model, arbitrary conditional flow (ACFlow), to learn the arbitrary
conditional distributions required for estimating the information metric. We
also learn a Bayesian network to accelerate the acquisition process. Our model
demonstrates superior performance over baselines evaluated in multiple
settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliva_J/0/1/0/all/0/1&quot;&gt;Junier B. Oliva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2006.09359">
<title>Accelerating Online Reinforcement Learning with Offline Datasets. (arXiv:2006.09359v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2006.09359</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) provides an appealing formalism for learning
control policies from experience. However, the classic active formulation of RL
necessitates a lengthy active exploration process for each behavior, making it
difficult to apply in real-world settings such as robotic control. If we can
instead allow RL algorithms to effectively use previously collected data to aid
the online learning process, such applications could be made substantially more
practical: the prior data would provide a starting point that mitigates
challenges due to exploration and sample complexity, while the online training
enables the agent to perfect the desired skill. Such prior data could either
constitute expert demonstrations or, more generally, sub-optimal prior data
that illustrates potentially useful transitions. But it remains difficult to
train a policy with potentially sub-optimal offline data and improve it further
with online RL. In this paper we systematically analyze why this problem is so
challenging, and propose an algorithm that combines sample-efficient dynamic
programming with maximum likelihood policy updates, providing a simple and
effective framework that is able to leverage large amounts of offline data and
then quickly perform online fine-tuning of RL policies. We show that our
method, advantage weighted actor critic (AWAC), enables rapid learning of
skills with a combination of prior demonstration data and online experience.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1&quot;&gt;Ashvin Nair&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dalal_M/0/1/0/all/0/1&quot;&gt;Murtaza Dalal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhishek Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2007.05239">
<title>Semi-supervised Learning for Aggregated Multilayer Graphs Using Diffuse Interface Methods and Fast Matrix Vector Products. (arXiv:2007.05239v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2007.05239</link>
<description rdf:parseType="Literal">&lt;p&gt;We generalize a graph-based multiclass semi-supervised classification
technique based on diffuse interface methods to multilayer graphs. Besides the
treatment of various applications with an inherent multilayer structure, we
present a very flexible approach that interprets high-dimensional data in a
low-dimensional multilayer graph representation. Highly efficient numerical
methods involving the spectral decomposition of the corresponding differential
graph operators as well as fast matrix-vector products based on the
nonequispaced fast Fourier transform (NFFT) enable the rapid treatment of large
and high-dimensional data sets. We perform various numerical tests putting a
special focus on image segmentation. In particular, we test the performance of
our method on data sets with up to 10 million nodes per layer as well as up to
104 dimensions resulting in graphs with up to 52 layers. While all presented
numerical experiments can be run on an average laptop computer, the linear
dependence per iteration step of the runtime on the network size in all stages
of our algorithm makes it scalable to even larger and higher-dimensional
problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergermann_K/0/1/0/all/0/1&quot;&gt;Kai Bergermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stoll_M/0/1/0/all/0/1&quot;&gt;Martin Stoll&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Volkmer_T/0/1/0/all/0/1&quot;&gt;Toni Volkmer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2007.08637">
<title>COV-ELM classifier: An Extreme Learning Machine based identification of COVID-19 using Chest X-Ray Images. (arXiv:2007.08637v4 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2007.08637</link>
<description rdf:parseType="Literal">&lt;p&gt;Coronaviruses constitute a family of viruses that gives rise to respiratory
diseases. COVID-19 is an infectious disease caused by a newly discovered
coronavirus also termed Severe acute respiratory syndrome coronavirus 2
(SARS-CoV-2). As COVID-19 is highly contagious, early diagnosis of COVID-19 is
crucial for an effective treatment strategy. However, the reverse
transcription-polymerase chain reaction (RT-PCR) test which is considered to be
a gold standard in the diagnosis of COVID-19 suffers from a high false-negative
rate. Therefore, the research community is exploring alternative diagnostic
mechanisms. Chest X-ray (CXR) image analysis has emerged as a feasible and
effective diagnostic technique towards this objective. In this work, we propose
the COVID-19 classification problem as a three-class classification problem
namely COVID-19, normal, and pneumonia. We propose a three-stage framework,
named COV-ELM based on extreme learning machine (ELM). Our dataset comprises
CXR images in a frontal view, namely Poster anterior (PA) and Erect
anteroposterior (AP). Stage one deals with preprocessing and transformation,
stage 2 deals with the challenge of extracting relevant features which are
passed as input to the ELM at the third stage, resulting in the identification
of COVID-19. The choice of ELM in this work has been motivated by its
significantly shorter training time as compared to conventional gradient-based
learning algorithms. As bigger and diverse datasets become available, it can be
quickly retrained as compared to its gradient-based competitor models. We use
10-fold cross-validation to evaluate the results of applying COV-ELM. The
COV-ELM achieved a macro average F1-score of 0.95 and the overall sensitivity
of ${0.94 \pm 0.02}$ at a 95% confidence interval. When compared to
state-of-the-art machine learning algorithms, the COV-ELM is found to
outperform its competitors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rajpal_S/0/1/0/all/0/1&quot;&gt;Sheetal Rajpal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Agarwal_M/0/1/0/all/0/1&quot;&gt;Manoj Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rajpal_A/0/1/0/all/0/1&quot;&gt;Ankit Rajpal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lakhyani_N/0/1/0/all/0/1&quot;&gt;Navin Lakhyani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kumar_N/0/1/0/all/0/1&quot;&gt;Naveen Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2007.14535">
<title>Dreaming: Model-based Reinforcement Learning by Latent Imagination without Reconstruction. (arXiv:2007.14535v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2007.14535</link>
<description rdf:parseType="Literal">&lt;p&gt;In the present paper, we propose a decoder-free extension of Dreamer, a
leading model-based reinforcement learning (MBRL) method from pixels. Dreamer
is a sample- and cost-efficient solution to robot learning, as it is used to
train latent state-space models based on a variational autoencoder and to
conduct policy optimization by latent trajectory imagination. However, this
autoencoding based approach often causes object vanishing, in which the
autoencoder fails to perceives key objects for solving control tasks, and thus
significantly limiting Dreamer&apos;s potential. This work aims to relieve this
Dreamer&apos;s bottleneck and enhance its performance by means of removing the
decoder. For this purpose, we firstly derive a likelihood-free and InfoMax
objective of contrastive learning from the evidence lower bound of Dreamer.
Secondly, we incorporate two components, (i) independent linear dynamics and
(ii) the random crop data augmentation, to the learning scheme so as to improve
the training performance. In comparison to Dreamer and other recent model-free
reinforcement learning methods, our newly devised Dreamer with InfoMax and
without generative decoder (Dreaming) achieves the best scores on 5 difficult
simulated robotics tasks, in which Dreamer suffers from object vanishing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Okada_M/0/1/0/all/0/1&quot;&gt;Masashi Okada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taniguchi_T/0/1/0/all/0/1&quot;&gt;Tadahiro Taniguchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2008.05859">
<title>Single-Photon Image Classification. (arXiv:2008.05859v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2008.05859</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantum computing-based machine learning mainly focuses on quantum computing
hardware that is experimentally challenging to realize due to requiring quantum
gates that operate at very low temperature. Instead, we demonstrate the
existence of a lower performance and much lower effort island on the
accuracy-vs-qubits graph that may well be experimentally accessible with room
temperature optics. This high temperature &quot;quantum computing toy model&quot; is
nevertheless interesting to study as it allows rather accessible explanations
of key concepts in quantum computing, in particular interference, entanglement,
and the measurement process.
&lt;/p&gt;
&lt;p&gt;We specifically study the problem of classifying an example from the MNIST
and Fashion-MNIST datasets, subject to the constraint that we have to make a
prediction after the detection of the very first photon that passed a
coherently illuminated filter showing the example. Whereas a classical set-up
in which a photon is detected after falling on one of the $28\times 28$ image
pixels is limited to a (maximum likelihood estimation) accuracy of $21.27\%$
for MNIST, respectively $18.27\%$ for Fashion-MNIST, we show that the
theoretically achievable accuracy when exploiting inference by optically
transforming the quantum state of the photon is at least $41.27\%$ for MNIST,
respectively $36.14\%$ for Fashion-MNIST.
&lt;/p&gt;
&lt;p&gt;We show in detail how to train the corresponding transformation with
TensorFlow and also explain how this example can serve as a teaching tool for
the measurement process in quantum mechanics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischbacher_T/0/1/0/all/0/1&quot;&gt;Thomas Fischbacher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sbaiz_L/0/1/0/all/0/1&quot;&gt;Luciano Sbaiz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2008.07257">
<title>FLBench: A Benchmark Suite for Federated Learning. (arXiv:2008.07257v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2008.07257</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning is a new machine learning paradigm. The goal is to build a
machine learning model from the data sets distributed on multiple devices
so-called an isolated data island, while keeping their data secure and private.
Most existing federated learning benchmarks work manually splits commonly used
public datasets into partitions to simulate real world isolated data island
scenarios. Still, this simulation fails to capture real world isolated data
island intrinsic characteristics. This paper presents a federated learning (FL)
benchmark suite named FLBench. FLBench contains three domains: medical,
financial, and AIoT. By configuring various domains, FLBench is qualified to
evaluate federated learning systems and algorithms essential aspects, like
communication, scenario transformation, privacy-preserving, data distribution
heterogeneity, and cooperation strategy. Hence, it becomes a promising platform
for developing novel federated learning algorithms. Currently, FLBench is open
sourced and in fast evolution. We package it as an automated deployment tool.
The benchmark suite is available from
https://www.benchcouncil.org/flbench.html.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yuan Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yange Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1&quot;&gt;Yanxia Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1&quot;&gt;Chunjie Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_J/0/1/0/all/0/1&quot;&gt;Jianfeng Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yunyou Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2008.12416">
<title>Regularized Densely-connected Pyramid Network for Salient Instance Segmentation. (arXiv:2008.12416v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2008.12416</link>
<description rdf:parseType="Literal">&lt;p&gt;Much of the recent efforts on salient object detection (SOD) have been
devoted to producing accurate saliency maps without being aware of their
instance labels. To this end, we propose a new pipeline for end-to-end salient
instance segmentation (SIS) that predicts a class-agnostic mask for each
detected salient instance. To better use the rich feature hierarchies in deep
networks and enhance the side predictions, we propose the regularized dense
connections, which attentively promote informative features and suppress
non-informative ones from all feature pyramids. A novel multi-level RoIAlign
based decoder is introduced to adaptively aggregate multi-level features for
better mask predictions. Such strategies can be well-encapsulated into the Mask
R-CNN pipeline. Extensive experiments on popular benchmarks demonstrate that
our design significantly outperforms existing \sArt competitors by 6.3\%
(58.6\% vs. 52.3\%) in terms of the AP metric.The code is available at
https://github.com/yuhuan-wu/RDPNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yu-Huan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Le Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1&quot;&gt;Wang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1&quot;&gt;Ming-Ming Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2009.06456">
<title>Label-Free Segmentation of COVID-19 Lesions in Lung CT. (arXiv:2009.06456v3 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2009.06456</link>
<description rdf:parseType="Literal">&lt;p&gt;Scarcity of annotated images hampers the building of automated solution for
reliable COVID-19 diagnosis and evaluation from CT. To alleviate the burden of
data annotation, we herein present a label-free approach for segmenting
COVID-19 lesions in CT via pixel-level anomaly modeling that mines out the
relevant knowledge from normal CT lung scans. Our modeling is inspired by the
observation that the parts of tracheae and vessels, which lay in the
high-intensity range where lesions belong to, exhibit strong patterns. To
facilitate the learning of such patterns at a pixel level, we synthesize
`lesions&apos; using a set of surprisingly simple operations and insert the
synthesized `lesions&apos; into normal CT lung scans to form training pairs, from
which we learn a normalcy-converting network (NormNet) that turns an &apos;abnormal&apos;
image back to normal. Our experiments on three different datasets validate the
effectiveness of NormNet, which conspicuously outperforms a variety of
unsupervised anomaly detection (UAD) methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yao_Q/0/1/0/all/0/1&quot;&gt;Qingsong Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xiao_L/0/1/0/all/0/1&quot;&gt;Li Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_P/0/1/0/all/0/1&quot;&gt;Peihang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;S. Kevin Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2009.09143">
<title>Active Learning for Product Type Ontology Enhancement in E-commerce. (arXiv:2009.09143v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2009.09143</link>
<description rdf:parseType="Literal">&lt;p&gt;Entity-based semantic search has been widely adopted in modern search engines
to improve search accuracy by understanding users&apos; intent. In e-commerce, an
accurate and complete product type (PT) ontology is essential for recognizing
product entities in queries and retrieving relevant products from catalog.
However, finding product types (PTs) to construct such an ontology is usually
expensive due to the considerable amount of human efforts it may involve. In
this work, we propose an active learning framework that efficiently utilizes
domain experts&apos; knowledge for PT discovery. We also show the quality and
coverage of the resulting PTs in the experiment results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zahiri_S/0/1/0/all/0/1&quot;&gt;Sayyed M. Zahiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiaqi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Han-Yu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Javed_F/0/1/0/all/0/1&quot;&gt;Faizan Javed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2009.11162">
<title>Implicit Gradient Regularization. (arXiv:2009.11162v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2009.11162</link>
<description rdf:parseType="Literal">&lt;p&gt;Gradient descent can be surprisingly good at optimizing deep neural networks
without overfitting and without explicit regularization. We find that the
discrete steps of gradient descent implicitly regularize models by penalizing
gradient descent trajectories that have large loss gradients. We call this
Implicit Gradient Regularization (IGR) and we use backward error analysis to
calculate the size of this regularization. We confirm empirically that implicit
gradient regularization biases gradient descent toward flat minima, where test
errors are small and solutions are robust to noisy parameter perturbations.
Furthermore, we demonstrate that the implicit gradient regularization term can
be used as an explicit regularizer, allowing us to control this gradient
regularization directly. More broadly, our work indicates that backward error
analysis is a useful theoretical approach to the perennial question of how
learning rate, model size, and parameter regularization interact to determine
the properties of overparameterized models optimized with gradient descent.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barrett_D/0/1/0/all/0/1&quot;&gt;David G.T. Barrett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dherin_B/0/1/0/all/0/1&quot;&gt;Benoit Dherin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2010.04925">
<title>Regularizing Neural Networks via Adversarial Model Perturbation. (arXiv:2010.04925v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2010.04925</link>
<description rdf:parseType="Literal">&lt;p&gt;Effective regularization techniques are highly desired in deep learning for
alleviating overfitting and improving generalization. In this paper, we propose
a new regularization scheme, based on the understanding that flat local minima
of the empirical risk cause the model to generalize better. This scheme is
referred to as adversarial model perturbation (AMP), where instead of directly
minimizing the empirical risk, an alternative &quot;AMP loss&quot; is minimized via SGD.
Specifically, the AMP loss is obtained from the empirical risk by applying the
&quot;worst&quot; norm-bounded perturbation on each point in the parameter space.
Comparing with most existing regularization schemes, AMP has strong theoretical
justifications, in that minimizing the AMP loss can be shown theoretically to
favour flat local minima of the empirical risk. Extensive experiments on
various modern deep architectures establish AMP as a new state of the art among
regularization schemes. Code is available at
https://github.com/hiyouga/AMP-Regularizer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1&quot;&gt;Yaowei Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Richong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1&quot;&gt;Yongyi Mao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2010.05265">
<title>Unsupervised Distillation of Syntactic Information from Contextualized Word Representations. (arXiv:2010.05265v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2010.05265</link>
<description rdf:parseType="Literal">&lt;p&gt;Contextualized word representations, such as ELMo and BERT, were shown to
perform well on various semantic and syntactic tasks. In this work, we tackle
the task of unsupervised disentanglement between semantics and structure in
neural language representations: we aim to learn a transformation of the
contextualized vectors, that discards the lexical semantics, but keeps the
structural information. To this end, we automatically generate groups of
sentences which are structurally similar but semantically different, and use
metric-learning approach to learn a transformation that emphasizes the
structural component that is encoded in the vectors. We demonstrate that our
transformation clusters vectors in space by structural properties, rather than
by lexical semantics. Finally, we demonstrate the utility of our distilled
representations by showing that they outperform the original contextualized
representations in a few-shot parsing setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1&quot;&gt;Shauli Ravfogel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elazar_Y/0/1/0/all/0/1&quot;&gt;Yanai Elazar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldberger_J/0/1/0/all/0/1&quot;&gt;Jacob Goldberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1&quot;&gt;Yoav Goldberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2010.08262">
<title>Towards truly local gradients with CLAPP: Contrastive, Local And Predictive Plasticity. (arXiv:2010.08262v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2010.08262</link>
<description rdf:parseType="Literal">&lt;p&gt;Back-propagation (BP) is costly to implement in hardware and implausible as a
learning rule implemented in the brain. However, BP is surprisingly successful
in explaining neuronal activity patterns found along the cortical processing
stream. We propose a locally implementable, unsupervised learning algorithm,
CLAPP, which minimizes a simple, layer-specific loss function, and thus does
not need to back-propagate error signals. The weight updates only depend on
state variables of the pre- and post-synaptic neurons and a layer-wide third
factor. Networks trained with CLAPP build deep hierarchical representations of
images and speech.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Illing_B/0/1/0/all/0/1&quot;&gt;Bernd Illing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gerstner_W/0/1/0/all/0/1&quot;&gt;Wulfram Gerstner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bellec_G/0/1/0/all/0/1&quot;&gt;Guillaume Bellec&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2010.08277">
<title>Probabilistic Surface Friction Estimation Based on Visual and Haptic Measurements. (arXiv:2010.08277v3 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2010.08277</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurately modeling local surface properties of objects is crucial to many
robotic applications, from grasping to material recognition. Surface properties
like friction are however difficult to estimate, as visual observation of the
object does not convey enough information over these properties. In contrast,
haptic exploration is time consuming as it only provides information relevant
to the explored parts of the object. In this work, we propose a joint
visuo-haptic object model that enables the estimation of surface friction
coefficient over an entire object by exploiting the correlation of visual and
haptic information, together with a limited haptic exploration by a robotic
arm. We demonstrate the validity of the proposed method by showing its ability
to estimate varying friction coefficients on a range of real multi-material
objects. Furthermore, we illustrate how the estimated friction coefficients can
improve grasping success rate by guiding a grasp planner toward high friction
areas.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1&quot;&gt;Tran Nguyen Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verdoja_F/0/1/0/all/0/1&quot;&gt;Francesco Verdoja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abu_Dakka_F/0/1/0/all/0/1&quot;&gt;Fares J. Abu-Dakka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kyrki_V/0/1/0/all/0/1&quot;&gt;Ville Kyrki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2011.03037">
<title>Teaching with Commentaries. (arXiv:2011.03037v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2011.03037</link>
<description rdf:parseType="Literal">&lt;p&gt;Effective training of deep neural networks can be challenging, and there
remain many open questions on how to best learn these models. Recently
developed methods to improve neural network training examine teaching:
providing learned information during the training process to improve downstream
model performance. In this paper, we take steps towards extending the scope of
teaching. We propose a flexible teaching framework using commentaries, learned
meta-information helpful for training on a particular task. We present
gradient-based methods to learn commentaries, leveraging recent work on
implicit differentiation for scalability. We explore diverse applications of
commentaries, from weighting training examples, to parameterising
label-dependent data augmentation policies, to representing attention masks
that highlight salient image regions. We find that commentaries can improve
training speed and/or performance, and provide insights about the dataset and
training process. We also observe that commentaries generalise: they can be
reused when training new models to obtain performance benefits, suggesting a
use-case where commentaries are stored with a dataset and leveraged in future
for improved model training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raghu_A/0/1/0/all/0/1&quot;&gt;Aniruddh Raghu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raghu_M/0/1/0/all/0/1&quot;&gt;Maithra Raghu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kornblith_S/0/1/0/all/0/1&quot;&gt;Simon Kornblith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1&quot;&gt;David Duvenaud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hinton_G/0/1/0/all/0/1&quot;&gt;Geoffrey Hinton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2011.15102">
<title>Learning by Passing Tests, with Application to Neural Architecture Search. (arXiv:2011.15102v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2011.15102</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning through tests is a broadly used methodology in human learning and
shows great effectiveness in improving learning outcome: a sequence of tests
are made with increasing levels of difficulty; the learner takes these tests to
identify his/her weak points in learning and continuously addresses these weak
points to successfully pass these tests. We are interested in investigating
whether this powerful learning technique can be borrowed from humans to improve
the learning abilities of machines. We propose a novel learning approach called
learning by passing tests (LPT). In our approach, a tester model creates
increasingly more-difficult tests to evaluate a learner model. The learner
tries to continuously improve its learning ability so that it can successfully
pass however difficult tests created by the tester. We propose a multi-level
optimization framework to formulate LPT, where the tester learns to create
difficult and meaningful tests and the learner learns to pass these tests. We
develop an efficient algorithm to solve the LPT problem. Our method is applied
for neural architecture search and achieves significant improvement over
state-of-the-art baselines on CIFAR-100, CIFAR-10, and ImageNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1&quot;&gt;Xuefeng Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Haochen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1&quot;&gt;Pengtao Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2012.04461">
<title>Combining Reinforcement Learning with Lin-Kernighan-Helsgaun Algorithm for the Traveling Salesman Problem. (arXiv:2012.04461v5 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2012.04461</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the Traveling Salesman Problem (TSP), a famous NP-hard
combinatorial optimization problem. And we propose a variable strategy
reinforced approach, denoted as VSR-LKH, which combines three reinforcement
learning methods (Q-learning, Sarsa and Monte Carlo) with the well-known TSP
algorithm, called Lin-Kernighan-Helsgaun (LKH). VSR-LKH replaces the inflexible
traversal operation in LKH, and lets the program learn to make choice at each
search step by reinforcement learning. Experimental results on 111 TSP
benchmarks from the TSPLIB with up to 85,900 cities demonstrate the excellent
performance of the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1&quot;&gt;Jiongzhi Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1&quot;&gt;Kun He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jianrong Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yan Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chu-Min Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2012.04863">
<title>Skillearn: Machine Learning Inspired by Humans&apos; Learning Skills. (arXiv:2012.04863v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2012.04863</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans, as the most powerful learners on the planet, have accumulated a lot
of learning skills, such as learning through tests, interleaving learning,
self-explanation, active recalling, to name a few. These learning skills and
methodologies enable humans to learn new topics more effectively and
efficiently. We are interested in investigating whether humans&apos; learning skills
can be borrowed to help machines to learn better. Specifically, we aim to
formalize these skills and leverage them to train better machine learning (ML)
models. To achieve this goal, we develop a general framework -- Skillearn,
which provides a principled way to represent humans&apos; learning skills
mathematically and use the formally-represented skills to improve the training
of ML models. In two case studies, we apply Skillearn to formalize two learning
skills of humans: learning by passing tests and interleaving learning, and use
the formalized skills to improve neural architecture search. Experiments on
various datasets show that trained using the skills formalized by Skillearn, ML
models achieve significantly better performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1&quot;&gt;Pengtao Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1&quot;&gt;Xuefeng Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ban_H/0/1/0/all/0/1&quot;&gt;Hao Ban&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2012.13681">
<title>Improving the Generalization of End-to-End Driving through Procedural Generation. (arXiv:2012.13681v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2012.13681</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the past few years there is a growing interest in the learning-based
self driving system. To ensure safety, such systems are first developed and
validated in simulators before being deployed in the real world. However, most
of the existing driving simulators only contain a fixed set of scenes and a
limited number of configurable settings. That might easily cause the
overfitting issue for the learning-based driving systems as well as the lack of
their generalization ability to unseen scenarios. To better evaluate and
improve the generalization of end-to-end driving, we introduce an open-ended
and highly configurable driving simulator called PGDrive, following a key
feature of procedural generation. Diverse road networks are first generated by
the proposed generation algorithm via sampling from elementary road blocks.
Then they are turned into interactive training environments where traffic flows
of nearby vehicles with realistic kinematics are rendered. We validate that
training with the increasing number of procedurally generated scenes
significantly improves the generalization of the agent across scenarios of
different traffic densities and road networks. Many applications such as
multi-agent traffic simulation and safe driving benchmark can be further built
upon the simulator. To facilitate the joint research effort of end-to-end
driving, we release the simulator and pretrained models at
https://decisionforce.github.io/pgdrive
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Quanyi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1&quot;&gt;Zhenghao Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qihang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chunxiao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1&quot;&gt;Bolei Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2101.02494">
<title>Corner case data description and detection. (arXiv:2101.02494v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2101.02494</link>
<description rdf:parseType="Literal">&lt;p&gt;As the major factors affecting the safety of deep learning models, corner
cases and related detection are crucial in AI quality assurance for
constructing safety- and security-critical systems. The generic corner case
researches involve two interesting topics. One is to enhance DL models
robustness to corner case data via the adjustment on parameters/structure. The
other is to generate new corner cases for model retraining and improvement.
However, the complex architecture and the huge amount of parameters make the
robust adjustment of DL models not easy, meanwhile it is not possible to
generate all real-world corner cases for DL training. Therefore, this paper
proposes to a simple and novel study aiming at corner case data detection via a
specific metric. This metric is developed on surprise adequacy (SA) which has
advantages on capture data behaviors. Furthermore, targeting at characteristics
of corner case data, three modifications on distanced-based SA are developed
for classification applications in this paper. Consequently, through the
experiment analysis on MNIST data and industrial data, the feasibility and
usefulness of the proposed method on corner case data detection are verified.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouyang_T/0/1/0/all/0/1&quot;&gt;Tinghui Ouyang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marco_V/0/1/0/all/0/1&quot;&gt;Vicent Sant Marco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Isobe_Y/0/1/0/all/0/1&quot;&gt;Yoshinao Isobe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asoh_H/0/1/0/all/0/1&quot;&gt;Hideki Asoh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oiwa_Y/0/1/0/all/0/1&quot;&gt;Yutaka Oiwa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seo_Y/0/1/0/all/0/1&quot;&gt;Yoshiki Seo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2101.08685">
<title>ItNet: iterative neural networks with small graphs for accurate and efficient anytime prediction. (arXiv:2101.08685v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2101.08685</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks have usually to be compressed and accelerated for their
usage in low-power, e.g. mobile, devices. Recently, massively-parallel hardware
accelerators were developed that offer high throughput and low latency at low
power by utilizing in-memory computation. However, to exploit these benefits
the computational graph of a neural network has to fit into the in-computation
memory of these hardware systems that is usually rather limited in size. In
this study, we introduce a class of network models that have a small memory
footprint in terms of their computational graphs. To this end, the graph is
designed to contain loops by iteratively executing a single network building
block. Furthermore, the trade-off between accuracy and latency of these
so-called iterative neural networks is improved by adding multiple intermediate
outputs both during training and inference. We show state-of-the-art results
for semantic segmentation on the CamVid and Cityscapes datasets that are
especially demanding in terms of computational resources. In ablation studies,
the improvement of network training by intermediate network outputs as well as
the trade-off between weight sharing over iterations and the network size are
investigated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfeil_T/0/1/0/all/0/1&quot;&gt;Thomas Pfeil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2101.10437">
<title>Deep Learning-Based Autoencoder for Data-Driven Modeling of an RF Photoinjector. (arXiv:2101.10437v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2101.10437</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling of large-scale research facilities is extremely challenging due to
complex physical processes and engineering problems. Here, we adopt a
data-driven approach to model the photoinector of European XFEL with a deep
learning-based autoencoder. A deep convolutional neural network (decoder) is
used to build images measured on the screen from a small feature map generated
by another neural network (encoder). We demonstrate that the autoencoder
trained only with experimental data can make high-fidelity predictions of
megapixel images for the longitudinal phase-space measurement. The prediction
significantly outperforms existing methods. We also show the scalability and
explicability of the autoencoder by sharing the same decoder with more than one
encoder used for different setups of the photoinjector, and propose a pragmatic
way to model a photoinjector with various diagnostics and working points. This
opens the door to a new way of accurately modeling a photoinjector using neural
networks. The approach can possibly be extended to the whole accelerator and
even other types of scientific facilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Ye Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brinker_F/0/1/0/all/0/1&quot;&gt;Frank Brinker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Decking_W/0/1/0/all/0/1&quot;&gt;Winfried Decking&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomin_S/0/1/0/all/0/1&quot;&gt;Sergey Tomin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schlarb_H/0/1/0/all/0/1&quot;&gt;Holger Schlarb&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2102.06483">
<title>Scalable Bayesian Inverse Reinforcement Learning. (arXiv:2102.06483v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2102.06483</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian inference over the reward presents an ideal solution to the
ill-posed nature of the inverse reinforcement learning problem. Unfortunately
current methods generally do not scale well beyond the small tabular setting
due to the need for an inner-loop MDP solver, and even non-Bayesian methods
that do themselves scale often require extensive interaction with the
environment to perform well, being inappropriate for high stakes or costly
applications such as healthcare. In this paper we introduce our method,
Approximate Variational Reward Imitation Learning (AVRIL), that addresses both
of these issues by jointly learning an approximate posterior distribution over
the reward that scales to arbitrarily complicated state spaces alongside an
appropriate policy in a completely offline manner through a variational
approach to said latent reward. Applying our method to real medical data
alongside classic control simulations, we demonstrate Bayesian reward inference
in environments beyond the scope of current methods, as well as task
performance competitive with focused offline imitation learning algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1&quot;&gt;Alex J. Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1&quot;&gt;Mihaela van der Schaar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2102.08093">
<title>A Law of Robustness for Weight-bounded Neural Networks. (arXiv:2102.08093v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2102.08093</link>
<description rdf:parseType="Literal">&lt;p&gt;Robustness of deep neural networks against adversarial perturbations is a
pressing concern motivated by recent findings showing the pervasive nature of
such vulnerabilities. One method of characterizing the robustness of a neural
network model is through its Lipschitz constant, which forms a robustness
certificate. A natural question to ask is, for a fixed model class (such as
neural networks) and a dataset of size $n$, what is the smallest achievable
Lipschitz constant among all models that fit the dataset? Recently, (Bubeck et
al., 2020) conjectured that when using two-layer networks with $k$ neurons to
fit a generic dataset, the smallest Lipschitz constant is
$\Omega(\sqrt{\frac{n}{k}})$. This implies that one would require one neuron
per data point to robustly fit the data. In this work we derive a lower bound
on the Lipschitz constant for any arbitrary model class with bounded Rademacher
complexity. Our result coincides with that conjectured in (Bubeck et al., 2020)
for two-layer networks under the assumption of bounded weights. However, due to
our result&apos;s generality, we also derive bounds for multi-layer neural networks,
discovering that one requires $\log n$ constant-sized layers to robustly fit
the data. Thus, our work establishes a law of robustness for weight bounded
neural networks and provides formal evidence on the necessity of
over-parametrization in deep learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Husain_H/0/1/0/all/0/1&quot;&gt;Hisham Husain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balle_B/0/1/0/all/0/1&quot;&gt;Borja Balle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.02826">
<title>Learning Accurate and Interpretable Decision Rule Sets from Neural Networks. (arXiv:2103.02826v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2103.02826</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a new paradigm for learning a set of independent logical
rules in disjunctive normal form as an interpretable model for classification.
We consider the problem of learning an interpretable decision rule set as
training a neural network in a specific, yet very simple two-layer
architecture. Each neuron in the first layer directly maps to an interpretable
if-then rule after training, and the output neuron in the second layer directly
maps to a disjunction of the first-layer rules to form the decision rule set.
Our representation of neurons in this first rules layer enables us to encode
both the positive and the negative association of features in a decision rule.
State-of-the-art neural net training approaches can be leveraged for learning
highly accurate classification models. Moreover, we propose a sparsity-based
regularization approach to balance between classification accuracy and the
simplicity of the derived rules. Our experimental results show that our method
can generate more accurate decision rule sets than other state-of-the-art
rule-learning algorithms with better accuracy-simplicity trade-offs. Further,
when compared with uninterpretable black-box machine learning approaches such
as random forests and full-precision deep neural networks, our approach can
easily find interpretable decision rule sets that have comparable predictive
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_L/0/1/0/all/0/1&quot;&gt;Litao Qiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Weijia Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1&quot;&gt;Bill Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.04551">
<title>Behavior From the Void: Unsupervised Active Pre-Training. (arXiv:2103.04551v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2103.04551</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new unsupervised pre-training method for reinforcement
learning called APT, which stands for Active Pre-Training. APT learns behaviors
and representations by actively searching for novel states in reward-free
environments. The key novel idea is to explore the environment by maximizing a
non-parametric entropy computed in an abstract representation space, which
avoids the challenging density modeling and consequently allows our approach to
scale much better in environments that have high-dimensional observations
(e.g., image observations). We empirically evaluate APT by exposing
task-specific reward after a long unsupervised pre-training phase. On Atari
games, APT achieves human-level performance on 12 games and obtains highly
competitive performance compared to canonical fully supervised RL algorithms.
On DMControl suite, APT beats all baselines in terms of asymptotic performance
and data efficiency and dramatically improves performance on tasks that are
extremely difficult to train from scratch.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.04564">
<title>Discovering Diverse Multi-Agent Strategic Behavior via Reward Randomization. (arXiv:2103.04564v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2103.04564</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a simple, general and effective technique, Reward Randomization
for discovering diverse strategic policies in complex multi-agent games.
Combining reward randomization and policy gradient, we derive a new algorithm,
Reward-Randomized Policy Gradient (RPG). RPG is able to discover multiple
distinctive human-interpretable strategies in challenging temporal trust
dilemmas, including grid-world games and a real-world game Agar.io, where
multiple equilibria exist but standard multi-agent policy gradient algorithms
always converge to a fixed one with a sub-optimal payoff for every player even
using state-of-the-art exploration techniques. Furthermore, with the set of
diverse strategies from RPG, we can (1) achieve higher payoffs by fine-tuning
the best policy from the set; and (2) obtain an adaptive agent by using this
set of strategies as its training opponents. The source code and example videos
can be found in our website: https://sites.google.com/view/staghuntrpg.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1&quot;&gt;Zhenggang Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1&quot;&gt;Chao Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Boyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Huazhe Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaolong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_F/0/1/0/all/0/1&quot;&gt;Fei Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Simon Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yi Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.05030">
<title>Optimal Program Synthesis Over Noisy Data. (arXiv:2103.05030v2 [cs.PL] UPDATED)</title>
<link>http://arxiv.org/abs/2103.05030</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore and formalize the task of synthesizing programs over noisy data,
i.e., data that may contain corrupted input-output examples. By formalizing the
concept of a Noise Source, an Input Source, and a prior distribution over
programs, we formalize the probabilistic process which constructs a noisy
dataset. This formalism allows us to define the correctness of a synthesis
algorithm, in terms of its ability to synthesize the hidden underlying program.
The probability of a synthesis algorithm being correct depends upon the match
between the Noise Source and the Loss Function used in the synthesis
algorithm&apos;s optimization process. We formalize the concept of an optimal Loss
Function given prior information about the Noise Source. We provide a technique
to design optimal Loss Functions given perfect and imperfect information about
the Noise Sources. We also formalize the concept and conditions required for
convergence, i.e., conditions under which the probability that the synthesis
algorithm produces a correct program increases as the size of the noisy data
set increases. This paper presents the first formalization of the concept of
optimal Loss Functions, the first closed form definition of optimal Loss
Functions, and the first conditions that ensure that a noisy synthesis
algorithm will have convergence guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Handa_S/0/1/0/all/0/1&quot;&gt;Shivam Handa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rinard_M/0/1/0/all/0/1&quot;&gt;Martin Rinard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.05863">
<title>AutoDO: Robust AutoAugment for Biased Data with Label Noise via Scalable Probabilistic Implicit Differentiation. (arXiv:2103.05863v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2103.05863</link>
<description rdf:parseType="Literal">&lt;p&gt;AutoAugment has sparked an interest in automated augmentation methods for
deep learning models. These methods estimate image transformation policies for
train data that improve generalization to test data. While recent papers
evolved in the direction of decreasing policy search complexity, we show that
those methods are not robust when applied to biased and noisy data. To overcome
these limitations, we reformulate AutoAugment as a generalized automated
dataset optimization (AutoDO) task that minimizes the distribution shift
between test data and distorted train dataset. In our AutoDO model, we
explicitly estimate a set of per-point hyperparameters to flexibly change
distribution of train data. In particular, we include hyperparameters for
augmentation, loss weights, and soft-labels that are jointly estimated using
implicit differentiation. We develop a theoretical probabilistic interpretation
of this framework using Fisher information and show that its complexity scales
linearly with the dataset size. Our experiments on SVHN, CIFAR-10/100, and
ImageNet classification show up to 9.3% improvement for biased datasets with
label noise compared to prior methods and, importantly, up to 36.6% gain for
underrepresented SVHN classes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gudovskiy_D/0/1/0/all/0/1&quot;&gt;Denis Gudovskiy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rigazio_L/0/1/0/all/0/1&quot;&gt;Luca Rigazio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ishizaka_S/0/1/0/all/0/1&quot;&gt;Shun Ishizaka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kozuka_K/0/1/0/all/0/1&quot;&gt;Kazuki Kozuka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsukizawa_S/0/1/0/all/0/1&quot;&gt;Sotaro Tsukizawa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.06369">
<title>Majority Voting with Bidirectional Pre-translation For Bitext Retrieval. (arXiv:2103.06369v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2103.06369</link>
<description rdf:parseType="Literal">&lt;p&gt;Obtaining high-quality parallel corpora is of paramount importance for
training NMT systems. However, as many language pairs lack adequate
gold-standard training data, a popular approach has been to mine so-called
&quot;pseudo-parallel&quot; sentences from paired documents in two languages. In this
paper, we outline some problems with current methods, propose computationally
economical solutions to those problems, and demonstrate success with novel
methods on the Tatoeba similarity search benchmark and on a downstream task,
namely NMT. We uncover the effect of resource-related factors (i.e. how much
monolingual/bilingual data is available for a given language) on the optimal
choice of bitext mining approach, and echo problems with the oft-used BUCC
dataset that have been observed by others. We make the code and data used for
our experiments publicly available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jones_A/0/1/0/all/0/1&quot;&gt;Alex Jones&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wijaya_D/0/1/0/all/0/1&quot;&gt;Derry Tanti Wijaya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.06727">
<title>Hybrid Physics and Deep Learning Model for Interpretable Vehicle State Prediction. (arXiv:2103.06727v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2103.06727</link>
<description rdf:parseType="Literal">&lt;p&gt;Physical motion models offer interpretable predictions for the motion of
vehicles. However, some model parameters, such as those related to aero- and
hydrodynamics, are expensive to measure and are often only roughly approximated
reducing prediction accuracy. Recurrent neural networks achieve high prediction
accuracy at low cost, as they can use cheap measurements collected during
routine operation of the vehicle, but their results are hard to interpret. To
precisely predict vehicle states without expensive measurements of physical
parameters, we propose a hybrid approach combining deep learning and physical
motion models including a novel two-phase training procedure. We achieve
interpretability by restricting the output range of the deep neural network as
part of the hybrid model, which limits the uncertainty introduced by the neural
network to a known quantity. We have evaluated our approach for the use case of
ship and quadcopter motion. The results show that our hybrid model can improve
model interpretability with no decrease in accuracy compared to existing deep
learning approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baier_A/0/1/0/all/0/1&quot;&gt;Alexandra Baier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boukhers_Z/0/1/0/all/0/1&quot;&gt;Zeyd Boukhers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Staab_S/0/1/0/all/0/1&quot;&gt;Steffen Staab&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>